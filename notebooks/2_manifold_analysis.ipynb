{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03b4e81",
   "metadata": {},
   "source": [
    "## Manifold Analysis\n",
    "\n",
    "#### 1. Load Distance Matrix\n",
    "This is the starting point where we load the distance matrix from the previous calculations for each of the projection directions. \n",
    "\n",
    "#### 2. Estimate Optimal Sigma\n",
    "We estimate the optimal sigma value for the Gaussian kernel, which is crucial for the diffusion map embedding.\n",
    "\n",
    "#### 3. Construct Laplacian Matrix\n",
    "From the distance matrix, we construct the Laplacian matrix, which represents the graph of data points. The construction can vary (e.g., using adjacency matrices, degree matrices, etc.), but it essentially captures the local geometry of the data.\n",
    "\n",
    "#### 4. Perform Spectral Decomposition\n",
    "We then decompose the Laplacian matrix to obtain its eigenvalues and eigenvectors. The eigenvectors serve as the new coordinates in the embedded space, while the eigenvalues can indicate the significance of each dimension.\n",
    "\n",
    "#### 5. Apply Manifold Trimming\n",
    "Based on a specified radius, we trim the dataset to refine its representation. This step involves removing outliers or points that are not within a defined core region of the data manifold.\n",
    "\n",
    "#### 6. Repeat Steps 2-5 for Refinement\n",
    "Depending on the results, we may need to iterate over the estimation of sigma, reconstruction of the Laplacian, spectral decomposition, and trimming to refine the manifold representation.\n",
    "\n",
    "#### 7. Save Final Outputs\n",
    "After reaching a satisfactory representation, we save the final set of points, embedding coordinates, eigenvalues, and any other relevant data for further analysis or visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigsh, ArpackNoConvergence\n",
    "from scipy.optimize import curve_fit, OptimizeWarning\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.datasets import make_s_curve\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from scipy.linalg import eigh\n",
    "import multiprocessing\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import traceback\n",
    "import mrcfile\n",
    "import pickle\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "from params import p\n",
    "project_name = \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e0de75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project name to before loading the parameters\n",
    "p.proj_name = project_name\n",
    "# When we call p.load(), it should attempt to load \"params_sample.toml\"\n",
    "p.load()\n",
    "# Print the parameters to verify they are loaded correctly\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f855f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NullEmitter:\n",
    "    \"\"\"\n",
    "    A class that provides a no-operation (no-op) implementation of an emitter.\n",
    "\n",
    "    This class is designed to be used in contexts where an emitter is required by the interface,\n",
    "    but no actual emitting action is desired. It effectively serves as a placeholder or a stub\n",
    "    that satisfies the requirement of having an emitter without performing any operation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def emit(self, percent):\n",
    "        \"\"\"\n",
    "        A no-operation implementation of the emit method.\n",
    "\n",
    "        This method is intended to fulfill the interface requirement for an emitting action\n",
    "        without performing any actual work. It can be used to ignore progress updates or\n",
    "        other emitting actions in a safe and controlled manner.\n",
    "\n",
    "        Parameters:\n",
    "        - percent (any): This parameter is accepted to match the expected interface of an\n",
    "          emitter method, but it is not used within the method. Any value passed to this\n",
    "          parameter will be ignored.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab8429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_print(msg: str=\"\"):\n",
    "    \"\"\"\n",
    "    Prints a debug message along with the caller's stack trace.\n",
    "\n",
    "    Parameters:\n",
    "    - msg (str): The debug message to print. If empty, only the stack trace is printed.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    if msg:\n",
    "        print(msg)\n",
    "    stack = traceback.format_stack()\n",
    "    print(stack[-2].split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59346c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fin1(filename):\n",
    "    \"\"\"\n",
    "    Reads and returns the data from a pickle file.\n",
    "\n",
    "    This function attempts to open a file in binary read mode and deserialize its contents using\n",
    "    pickle. If an exception occurs during this process, it logs the exception message using\n",
    "    `debug_print` and returns None.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The path to the file to be read.\n",
    "\n",
    "    Returns:\n",
    "    - The deserialized data from the file if successful, None otherwise.\n",
    "    \"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        try:\n",
    "            data = pickle.load(f)\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            debug_print(str(e))\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f4c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fout1(filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Writes the given keyword arguments to a file using pickle serialization.\n",
    "\n",
    "    This function opens a file in binary write mode and serializes the keyword arguments passed to\n",
    "    it using pickle, with the highest available protocol. It ensures that the data is written\n",
    "    efficiently and securely.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The path to the file where the data will be written.\n",
    "    - **kwargs: Arbitrary keyword arguments that will be serialized and written to the file.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(kwargs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # Note: The file is automatically closed when exiting the 'with' block, so f.close() is not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2751e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fergusonE(D, logEps, a0=None):\n",
    "    \"\"\"\n",
    "    Fits a curve using a hyperbolic tangent function to the data provided and returns the optimized parameters.\n",
    "\n",
    "    This function attempts to fit a curve defined by a hyperbolic tangent function to the given data points.\n",
    "    It uses the scipy.optimize.curve_fit method for curve fitting. The function also calculates the threshold\n",
    "    for weighting the data points based on the provided logarithmic epsilon values and distances.\n",
    "\n",
    "    Parameters:\n",
    "    - D (np.ndarray): An array of distances between data points.\n",
    "    - logEps (np.ndarray): An array of logarithmic epsilon values to be used for curve fitting.\n",
    "    - a0 (np.ndarray, optional): Initial guess for the parameters of the hyperbolic tangent function.\n",
    "      If None, a default value of ones(4) is used.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the following elements:\n",
    "        - popt (np.ndarray): Optimal values for the parameters so that the sum of the squared residuals\n",
    "          of fun(xdata, *popt) - ydata is minimized.\n",
    "        - logSumWij (np.ndarray): Logarithm of the sum of weighted distances for each logEps value.\n",
    "        - resnorm (float): The sum of the square roots of the absolute values of the diagonal of the\n",
    "          covariance matrix of the parameters.\n",
    "        - R_squared (float): Coefficient of determination, indicating the proportion of the variance in\n",
    "          the dependent variable that is predictable from the independent variable(s).\n",
    "\n",
    "    Notes:\n",
    "    - The function internally defines a `fun` function representing a hyperbolic tangent model and a\n",
    "      `find_thres` function to calculate a threshold for weighting the data points.\n",
    "    - The curve fitting process iterates until the residual norm (resnorm) is less than 100, adjusting\n",
    "      the initial guess for the parameters (a0) in each iteration if necessary.\n",
    "    - This function uses scipy's curve_fit method, which may not converge to a solution; in such cases,\n",
    "      it prints the residual norm, the parameters attempted, and the error identifier (ier).\n",
    "    \"\"\"\n",
    "    if a0 is None:\n",
    "        a0 = np.ones(4)\n",
    "    def fun(x, a, b, c, d):\n",
    "        return d + c * np.tanh(a * x + b)\n",
    "    def find_thres(logEps, D2):\n",
    "        d = 0.5 * D2 / np.exp(np.max(logEps))\n",
    "        ss = np.sum(np.exp(-d))\n",
    "        return max(-np.log(0.01 * ss / len(D2)), 10)  # Taking 1% of the average (10)\n",
    "    # Range of values to try:\n",
    "    logSumWij = np.empty_like(logEps)\n",
    "    D2 = D * D\n",
    "    thr = find_thres(logEps, D2)\n",
    "    for k, le in enumerate(logEps):\n",
    "        d = 0.5 * D2 / np.exp(le)\n",
    "        Wij = np.exp(-d[d < thr])  # See Coifman 2008\n",
    "        logSumWij[k] = np.log(np.sum(Wij))\n",
    "    # Curve fitting of a tanh():\n",
    "    resnorm = np.inf\n",
    "    while (resnorm > 100):\n",
    "        popt, pcov, infodict, mesg, ier = curve_fit(fun, logEps, logSumWij, p0=a0, full_output=True)\n",
    "        resnorm = np.sum(np.sqrt(np.fabs(np.diag(pcov))))\n",
    "        if ier < 1 or ier > 4:\n",
    "            print(resnorm, popt, ier)\n",
    "        a0 *= 0.5\n",
    "        residuals = logSumWij - fun(logEps, *popt)\n",
    "        ss_res = np.sum(residuals**2)  # Residual sum of squares\n",
    "        ss_tot = np.sum((logSumWij - np.mean(logSumWij))**2)  # Total sum of squares\n",
    "        R_squared = 1 - (ss_res / ss_tot)  # R**2 value\n",
    "    return (popt, logSumWij, resnorm, R_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad913421",
   "metadata": {},
   "source": [
    "### Example illustration for the fergusonE function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dcc55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(42)\n",
    "logEps = np.linspace(-5, 5, 200)  # Extended range for logEps\n",
    "D = np.linspace(0, 20, 200)  # Extended range for distances\n",
    "\n",
    "# Generate true logSumWij values with a complex relationship\n",
    "true_params1 = [0.5, 0.1, 2.0, 0.5]\n",
    "true_params2 = [-0.3, -0.2, -1.5, 1.0]\n",
    "true_logSumWij = true_params1[3] + true_params1[2] * np.tanh(true_params1[0] * logEps + true_params1[1]) \\\n",
    "                + true_params2[3] + true_params2[2] * np.tanh(true_params2[0] * logEps + true_params2[1]) \\\n",
    "                + np.random.normal(0, 0.3, size=logEps.shape)\n",
    "\n",
    "# Fit the curve with an initial guess far from the true parameters\n",
    "a0 = np.array([2.0, 2.0, -2.0, -2.0])\n",
    "popt, logSumWij, resnorm, R_squared = fergusonE(D, logEps, a0)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(logEps, true_logSumWij, label='True Data', color='blue', alpha=0.5)\n",
    "plt.plot(logEps, logSumWij, label='Fitted Curve', color='red', linewidth=2)\n",
    "plt.title('Complex Curve Fitting using FergusonE Function')\n",
    "plt.xlabel('logEps')\n",
    "plt.ylabel('logSumWij')\n",
    "plt.legend()\n",
    "plt.axis('on')\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "# Output the optimized parameters and goodness-of-fit measures\n",
    "print(f\"Optimized parameters: {popt}\")\n",
    "print(f\"Residual norm: {resnorm}\")\n",
    "print(f\"R-squared: {R_squared}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eaf93852",
   "metadata": {},
   "source": [
    "********  DMembeddingII  ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e8f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slaplacian(*arg):\n",
    "    \"\"\"\n",
    "    Given a set of nS data points, and the distances to nN nearest neighbors\n",
    "    for each data point, slaplacian computes a sparse, nY by nY symmetric\n",
    "    graph Laplacian matrix l.\n",
    "\n",
    "    The input data are supplied in the column vectors yVal and yInd of length\n",
    "    nY * nN such that\n",
    "\n",
    "    yVal( ( i - 1 ) * nN + ( 1 : nN ) ) contains the distances to the\n",
    "    nN nearest neighbors of data point i sorted in ascending order, and\n",
    "\n",
    "    yInd( ( i - 1 ) * nN + ( 1 : nN ) ) contains the indices of the nearest\n",
    "    neighbors.\n",
    "\n",
    "    yVal and yInd can be computed by calling nndist\n",
    "\n",
    "    slaplacian admits a number of options passed as name-value pairs\n",
    "\n",
    "    alpha : normalization, according to Coifman & Lafon\n",
    "\n",
    "    nAutotune : number of nearest neighbors for autotuning. Set to zero if no\n",
    "    autotuning is to be performed\n",
    "\n",
    "    sigma: width of the Gaussian kernel\n",
    "    \"\"\"\n",
    "    yVal = arg[0]\n",
    "    yCol = arg[1]\n",
    "    yRow = arg[2]\n",
    "    nS = arg[3]  # dataset size\n",
    "    options = arg[4]  # options.sigma: Gaussian width\n",
    "    nNZ = len(yVal)  # Number of nonzero elements\n",
    "\n",
    "    # If required, compute autotuning distances:\n",
    "    if options.autotune > 0:\n",
    "        print('Autotuning is not implemented in this version of slaplacian' + '\\n')\n",
    "    else:\n",
    "        sigmaTune = options.sigma\n",
    "\n",
    "    yVal = yVal / sigmaTune**2\n",
    "    # Compute the unnormalized weight matrix:\n",
    "    yVal = np.exp(-yVal)  # apply exponential weights (yVal is distance**2)\n",
    "    l = csc_matrix((yVal, (yRow, yCol)), shape=(nS, nS))\n",
    "    d = np.array(l.sum(axis=0)).T\n",
    "\n",
    "    if options.alpha != 1:  # apply non-isotropic normalization\n",
    "        d = d**options.alpha\n",
    "\n",
    "    yVal = yVal / (d[yRow].flatten('C') * d[yCol].flatten('C'))\n",
    "    l = csc_matrix((yVal, (yRow, yCol)), shape=(nS, nS))\n",
    "\n",
    "    # Normalize by the degree matrix to form normalized graph Laplacian:\n",
    "    d = np.array(l.sum(axis=0))\n",
    "    d = np.sqrt(d).T\n",
    "    yVal = yVal / (d[yRow].flatten('C') * d[yCol].flatten('C'))\n",
    "    l = csc_matrix((yVal, (yRow, yCol)), shape=(nS, nS))\n",
    "    l = np.abs(l + l.T) / 2.0  # iron out numerical wrinkles\n",
    "    temp = l - l.T\n",
    "\n",
    "    return (l, sigmaTune)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c8c56",
   "metadata": {},
   "source": [
    "### Example illustration for the slaplacian function\n",
    "\n",
    "To demonstrate the slaplacian function, we need to simulate a scenario where we have a set of data points and their distances to their nearest neighbors. We will simulate a small dataset and compute the sparse graph Laplacian matrix using the slaplacian function.\n",
    "\n",
    "1. Simulating data points: We will create a simple set of data points.\n",
    "\n",
    "2. Computing nearest neighbors and distances: Although the real computation of nearest neighbors and distances (yVal and yCol) would require a method like nndist, for simplicity, we will simulate these values directly.\n",
    "\n",
    "3. Using slaplacian: We will pass these simulated values to slaplacian along with a set of options.\n",
    "\n",
    "4. Visualizing the Laplacian matrix: To illustrate the output, we will visualize the sparse graph Laplacian matrix as a heatmap.\n",
    "\n",
    "#### Note: The warnings indicate two common numerical issues encountered during the computation of the graph Laplacian matrix:\n",
    "\n",
    "1. Divide by Zero: This warning arises when there are zero values in the degree matrix d, leading to division by zero during normalization. This situation can occur if some nodes in the graph are isolated (i.e., have no edges connecting them to other nodes), resulting in a zero degree.\n",
    "\n",
    "2. Invalid Values in Multiplication: This warning typically follows the divide by zero warning and indicates that the operation has resulted in NaN (Not a Number) or inf (infinity) values in the array. This is a consequence of attempting to normalize using invalid or zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65428b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate input data for the slaplacian function\n",
    "nS = 10  # Number of data points\n",
    "nN = 3   # Number of nearest neighbors for each data point\n",
    "yVal = np.random.rand(nS * nN)  # Random distances to nearest neighbors\n",
    "print(yVal)\n",
    "yCol = np.tile(np.arange(nN), nS)  # Column indices for nearest neighbors\n",
    "print(yCol)\n",
    "yRow = np.sort(np.random.choice(nS, nS * nN, replace=True))  # Row indices, simulated\n",
    "print(yRow)\n",
    "\n",
    "# Define options for the slaplacian function\n",
    "options = namedtuple('Options', 'sigma alpha autotune')(sigma=1.0, alpha=0.5, autotune=0)\n",
    "\n",
    "# Compute the Laplacian matrix using the slaplacian function\n",
    "l, sigmaTune = slaplacian(yVal, yCol, yRow, nS, options)\n",
    "\n",
    "# Convert the sparse Laplacian matrix to a dense format for visualization\n",
    "l_dense = l.toarray()\n",
    "print(l_dense)\n",
    "\n",
    "# Visualize the Laplacian matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(l_dense, cmap='viridis', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.axis('on')\n",
    "plt.grid(False)\n",
    "plt.title('Heatmap of the Graph Laplacian Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eeff45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sembedding(yVal, yCol, yRow, nS, options1):\n",
    "    \"\"\"\n",
    "    Laplacian eigenfunction embedding using sparse arrays.\n",
    "\n",
    "    This function computes the eigenvalues and eigenvectors of the Laplacian matrix of a graph,\n",
    "    which represents the dataset. The Laplacian matrix is constructed based on the input sparse\n",
    "    matrix components (values, column indices, row pointers) and options specifying the embedding\n",
    "    parameters.\n",
    "\n",
    "    Parameters:\n",
    "    - yVal (np.ndarray): The values of the non-zero elements in the sparse matrix representation.\n",
    "    - yCol (np.ndarray): The column indices of the non-zero elements in the sparse matrix.\n",
    "    - yRow (np.ndarray): The row indices of the non-zero elements in the sparse matrix.\n",
    "    - nS (int): The number of samples or nodes in the graph.\n",
    "    - options1 (namedtuple): A namedtuple containing the options for the embedding. Expected fields\n",
    "      are sigma (float), alpha (float), visual (bool), nEigs (int), and autotune (int).\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the following elements:\n",
    "        - vals (np.ndarray): The computed eigenvalues of the Laplacian matrix.\n",
    "        - vecs (np.ndarray): The computed eigenvectors of the Laplacian matrix, corresponding to the eigenvalues.\n",
    "\n",
    "    Notes:\n",
    "    - The function attempts to compute the specified number of eigenvalues and eigenvectors using\n",
    "      the ARPACK solver via scipy.sparse.linalg.eigsh. If the solver does not converge within the\n",
    "      specified maximum number of iterations, it catches the ArpackNoConvergence exception and\n",
    "      returns the eigenvalues and eigenvectors that were computed up to that point.\n",
    "    \"\"\"\n",
    "    # Create a new options namedtuple with values from options1\n",
    "    options = namedtuple('options', 'sigma alpha visual nEigs autotune')\n",
    "    options.sigma = options1.sigma\n",
    "    options.alpha = options1.alpha\n",
    "    options.nEigs = options1.nEigs\n",
    "    options.autotune = 0  # Autotuning is disabled in this implementation\n",
    "\n",
    "    # Compute the sparse Laplacian matrix\n",
    "    l, sigmaTune = slaplacian(yVal, yCol, yRow, nS, options)\n",
    "\n",
    "    # Attempt to compute the eigenvalues and eigenvectors of the Laplacian matrix\n",
    "    try:\n",
    "        vals, vecs = eigsh(l, k=options.nEigs + 1, maxiter=300, v0=np.ones(nS), return_eigenvectors=True)\n",
    "    except ArpackNoConvergence as e:\n",
    "        # Handle the case where ARPACK does not converge within the maximum number of iterations\n",
    "        vals = e.eigenvalues\n",
    "        vecs = e.eigenvectors\n",
    "        print(\"eigsh not converging in 300 iterations...\")\n",
    "\n",
    "    # Sort the eigenvalues and eigenvectors in descending order\n",
    "    ix = np.argsort(vals)[::-1]\n",
    "    vals = vals[ix]\n",
    "    vecs = vecs[:, ix]\n",
    "\n",
    "    return (vals, vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4408fdf4",
   "metadata": {},
   "source": [
    "### Example illustration for the sembedding function\n",
    "\n",
    "Let us go through the process to compute the eigenvalues and eigenvectors for graph embedding and visualize the 2D embedding. We will simulate the input data compatible with these functions and follow through with the visualization.\n",
    "\n",
    "1. Simulate Input Data: Generate appropriate input data for the slaplacian function.\n",
    "\n",
    "2. Compute the Laplacian Matrix: Use the slaplacian function to compute the Laplacian matrix of the graph.\n",
    "\n",
    "3. Compute Embedding: Apply the sembedding function to obtain the eigenvalues and eigenvectors, which will be used for embedding.\n",
    "\n",
    "4. Visualization: Visualize the first two non-trivial eigenvectors as a 2D embedding of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e74b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate input data for slaplacian and sembedding\n",
    "nS = 100  # Number of samples/nodes\n",
    "yVal = np.random.rand(nS * 10)  # Simulated distances\n",
    "yCol = np.tile(np.arange(10), nS)  # Simulated column indices\n",
    "yRow = np.repeat(np.arange(nS), 10)  # Simulated row indices\n",
    "\n",
    "# Options for slaplacian and sembedding\n",
    "options1 = namedtuple('Options', 'sigma alpha visual nEigs autotune')(\n",
    "    sigma=1.0, \n",
    "    alpha=1.0, \n",
    "    visual=False, \n",
    "    nEigs=2, \n",
    "    autotune=0\n",
    ")\n",
    "\n",
    "# Compute the embedding\n",
    "vals, vecs = sembedding(yVal, yCol, yRow, nS, options1)\n",
    "\n",
    "# Visualization of the 2D embedding\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(vecs[:, 1], vecs[:, 2], c='blue', alpha=0.6)\n",
    "plt.title('2D Embedding of Graph Nodes')\n",
    "plt.xlabel('First Non-Trivial Eigenvector')\n",
    "plt.ylabel('Second Non-Trivial Eigenvector')\n",
    "plt.axis('on')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790e566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yColVal(params):\n",
    "    \"\"\"\n",
    "    Processes and updates arrays for values and column indices in a sparse matrix representation.\n",
    "\n",
    "    This function takes a set of parameters related to the sparse matrix construction, including\n",
    "    arrays of values and indices, and updates these arrays based on the provided batch of data.\n",
    "    It is typically used in the context of constructing or updating a sparse representation of a\n",
    "    graph or matrix, especially when dealing with large datasets that require batching.\n",
    "\n",
    "    Parameters:\n",
    "    - params (tuple): A tuple containing the following elements:\n",
    "        - yVal (np.ndarray): The values of the non-zero elements in the sparse matrix.\n",
    "        - yVal1 (np.ndarray): The original values from which yVal will be updated.\n",
    "        - yCol (np.ndarray): The column indices of the non-zero elements in the sparse matrix.\n",
    "        - yInd1 (np.ndarray): The original indices from which yCol will be updated.\n",
    "        - nB (int): The batch size, indicating the number of data points processed in this batch.\n",
    "        - nN (int): The number of nearest neighbors considered for each data point.\n",
    "        - nNIn (int): The initial number of nearest neighbors before filtering.\n",
    "        - jStart (int): The start index of the current batch.\n",
    "        - jEnd (int): The end index of the current batch.\n",
    "        - indStart (int): The start index for updating yVal and yCol.\n",
    "        - indEnd (int): The end index for updating yVal and yCol.\n",
    "        - iBatch (int): The current batch number.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the updated yCol and yVal arrays.\n",
    "\n",
    "    Notes:\n",
    "    - The function reshapes and filters the input arrays yVal1 and yInd1 based on the batch\n",
    "      information and the number of nearest neighbors. It then updates the yVal and yCol arrays\n",
    "      with the processed data for the current batch.\n",
    "    - This function is part of a larger process of constructing or updating sparse matrices and\n",
    "      is designed to handle data in batches for efficiency and scalability.\n",
    "    \"\"\"\n",
    "    yVal = params[0]\n",
    "    yVal1 = params[1]\n",
    "    yCol = params[2]\n",
    "    yInd1 = params[3]\n",
    "    nB = params[4]\n",
    "    nN = params[5]\n",
    "    nNIn = params[6]\n",
    "    jStart = params[7]\n",
    "    jEnd = params[8]\n",
    "    indStart = params[9]\n",
    "    indEnd = params[10]\n",
    "    iBatch = params[11]\n",
    "\n",
    "    # Reshape and filter the data batch for values\n",
    "    DataBatch = yVal1\n",
    "    DataBatch = DataBatch.reshape(nB, nNIn).T\n",
    "    DataBatch = DataBatch[:nN, :]\n",
    "    DataBatch[0, :] = 0  # Reset the first row to zeros\n",
    "    yVal[indStart:indEnd] = DataBatch.reshape(nN * nB, 1)\n",
    "\n",
    "    # Reshape and filter the data batch for column indices\n",
    "    DataBatch = yInd1\n",
    "    DataBatch = DataBatch.reshape(nB, nNIn).T\n",
    "    DataBatch = DataBatch[:nN, :]\n",
    "    yCol[indStart:indEnd] = DataBatch.reshape(nN * nB, 1).astype(float)\n",
    "\n",
    "    return (yCol, yVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ede5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(nS, nN, D):\n",
    "    \"\"\"\n",
    "    Initializes the arrays of indices and values for constructing a sparse matrix\n",
    "    representation of distances between data points.\n",
    "\n",
    "    This function processes a distance matrix to identify the nearest neighbors for each\n",
    "    data point. It then creates arrays that store the indices of these neighbors and the\n",
    "    corresponding distance values. The first distance value for each data point is set to\n",
    "    zero to indicate self-distance, ensuring the diagonal of the distance matrix is zero.\n",
    "\n",
    "    Parameters:\n",
    "    - nS (int): The number of samples or data points.\n",
    "    - nN (int): The number of nearest neighbors to consider for each data point.\n",
    "    - D (np.ndarray): A square distance matrix of shape (nS, nS) where D[i, j] represents\n",
    "      the distance between the i-th and j-th data points.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing two flattened arrays:\n",
    "        - yInd1 (np.ndarray): A flattened array of indices of the nearest neighbors for each data point.\n",
    "        - yVal1 (np.ndarray): A flattened array of the corresponding distance values to the nearest neighbors.\n",
    "\n",
    "    Notes:\n",
    "    - The function modifies the input distance matrix D by setting the diagonal elements to\n",
    "      negative infinity to ensure that each data point's self-distance does not affect the\n",
    "      nearest neighbors' calculation.\n",
    "    - After identifying the nearest neighbors and their distances, the function resets the\n",
    "      first distance value for each data point to zero, effectively ignoring self-distance\n",
    "      in the sparse matrix representation.\n",
    "    \"\"\"\n",
    "    yInd1 = np.zeros((nN, nS), dtype='int32')\n",
    "    yVal1 = np.zeros((nN, nS), dtype='float64')\n",
    "    \n",
    "    for iS in range(nS):\n",
    "        D[iS, iS] = -np.Inf  # Force this distance to be the minimal value\n",
    "        B = np.sort(D[:, iS])\n",
    "        IX = np.argsort(D[:, iS])\n",
    "        yInd1[:, iS] = IX[:nN]\n",
    "        yVal1[:, iS] = B[:nN]\n",
    "        yVal1[0, iS] = 0  # Set this distance back to zero\n",
    "    \n",
    "    yInd1 = yInd1.flatten('F')\n",
    "    yVal1 = yVal1.flatten('F')\n",
    "    \n",
    "    return (yInd1, yVal1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81302dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_matrix0(Row, Col, Val, nZ, nS):\n",
    "    \"\"\"\n",
    "    Constructs a symmetric matrix from given row indices, column indices, and values,\n",
    "    specifically designed for handling squared distances.\n",
    "\n",
    "    This function first creates a sparse matrix from the given row indices, column indices,\n",
    "    and values. It then converts this sparse matrix to a dense array and performs operations\n",
    "    to ensure that the resulting matrix is symmetric and represents squared distances\n",
    "    correctly.\n",
    "\n",
    "    Parameters:\n",
    "    - Row (np.ndarray): An array of row indices for the non-zero elements in the matrix.\n",
    "    - Col (np.ndarray): An array of column indices for the non-zero elements in the matrix.\n",
    "    - Val (np.ndarray): An array of values corresponding to the non-zero elements in the matrix.\n",
    "    - nZ (int): The number of zero elements in the matrix. This parameter is accepted but not\n",
    "      directly used in the function, indicating potential use in extended functionality or\n",
    "      error checking.\n",
    "    - nS (int): The size of the square matrix to be constructed, indicating both the number\n",
    "      of rows and columns.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A symmetric matrix constructed from the input parameters, with adjustments\n",
    "      to ensure correct representation of squared distances.\n",
    "\n",
    "    Notes:\n",
    "    - The function first constructs a sparse CSR (Compressed Sparse Row) matrix from the input\n",
    "      indices and values. It then converts this sparse matrix to a dense array.\n",
    "    - It computes the square of the dense array and its transpose to handle squared distances.\n",
    "    - The final matrix is adjusted by adding the original matrix and its transpose, then\n",
    "      subtracting a matrix that contains the squares of the distances, to ensure symmetry\n",
    "      and correct distance representation.\n",
    "    \"\"\"\n",
    "    # Create a sparse CSR matrix from the given indices and values\n",
    "    y = csr_matrix((Val, (Row, Col)), shape=(nS, nS)).toarray()\n",
    "    \n",
    "    # Compute the square of the dense array and its transpose\n",
    "    y2 = y * y.T  # y2 contains the squares of the distances\n",
    "    \n",
    "    # Square the original matrix\n",
    "    y = y**2\n",
    "    \n",
    "    # Adjust the matrix to ensure symmetry and correct representation of squared distances\n",
    "    y = y + y.T - y2\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b83c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_matrix1(Row, Col, Val, nZ, nS):\n",
    "    \"\"\"\n",
    "    Constructs a symmetric matrix from given row indices, column indices, and values.\n",
    "    This version simplifies the process by directly adjusting for symmetry without explicitly\n",
    "    squaring the matrix values.\n",
    "\n",
    "    Parameters:\n",
    "    - Row (np.ndarray): An array of row indices for the non-zero elements in the matrix.\n",
    "    - Col (np.ndarray): An array of column indices for the non-zero elements in the matrix.\n",
    "    - Val (np.ndarray): An array of values corresponding to the non-zero elements in the matrix.\n",
    "    - nZ (int): The number of zero elements in the matrix. This parameter is accepted but not\n",
    "      directly used in the function, indicating potential use in extended functionality or\n",
    "      error checking.\n",
    "    - nS (int): The size of the square matrix to be constructed, indicating both the number\n",
    "      of rows and columns.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A symmetric matrix constructed from the input parameters. The symmetry is\n",
    "      achieved by adding the matrix to its transpose and then subtracting the element-wise\n",
    "      product of the matrix and its transpose.\n",
    "\n",
    "    Notes:\n",
    "    - The function constructs a sparse CSR (Compressed Sparse Row) matrix from the input indices\n",
    "      and values and then converts this sparse matrix to a dense array.\n",
    "    - It ensures the symmetry of the resulting matrix by adding it to its transpose and\n",
    "      subtracting the element-wise product of the matrix and its transpose, which contains\n",
    "      the squares of the original distances. This operation corrects for any asymmetries\n",
    "      that might arise from the input data or the sparse matrix construction process.\n",
    "    \"\"\"\n",
    "    # Create a sparse CSR matrix from the given indices and values\n",
    "    y = csr_matrix((Val, (Row, Col)), shape=(nS, nS)).toarray()\n",
    "    \n",
    "    # Compute the element-wise product of the matrix and its transpose\n",
    "    y2 = y * y.T  # y2 contains the squares of the distances\n",
    "    \n",
    "    # Adjust the matrix to ensure symmetry\n",
    "    y = y + y.T - y2\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a388e6",
   "metadata": {},
   "source": [
    "### DMembeddingIIop \n",
    "\n",
    "The DMembeddingIIop function performs diffusion maps embedding on a given distance matrix D with several steps involved.\n",
    "\n",
    "#### Step 1: Initialization\n",
    "\n",
    "    - The function initializes by defining the number of samples (nS) and the number of nearest neighbors (nN) based on the input distance matrix D and the parameter k.\n",
    "\n",
    "    - It calls initialize to presumably prepare initial indices and values (yInd1, yVal1) for constructing a neighbor graph from D.\n",
    "\n",
    "#### Step 2: Constructing Neighbor Graph\n",
    "\n",
    "    - The distance matrix D is processed in batches (nBatch), each containing a subset of the data points (nB).\n",
    "    \n",
    "    - For each batch, it computes linear indices for diffraction patterns and updates values (yVal) and column indices (yCol) for the neighbor graph using get_yColVal.\n",
    "\n",
    "    - After processing all batches, it symmetrizes the distance matrix to ensure it represents an undirected graph.\n",
    "\n",
    "#### Step 3: Symmetrization of the Distance Matrix\n",
    "\n",
    "    - Nonzero distances are identified (yRowNZ, yColNZ, yValNZ), and a sparse matrix y is constructed to represent the symmetrized neighbor graph.\n",
    "\n",
    "    - Zero distances are processed separately, and their count (nZ) is updated.\n",
    "\n",
    "#### Step 4: Diffusion Operator Construction\n",
    "\n",
    "    - A Gaussian kernel width (sigma) is determined through autotuning, using the fergusonE function to optimize over logarithmically spaced logEps values.\n",
    "\n",
    "    - The function decides on the kernel normalization parameter (alpha) based on the autotuning result and the user-provided tune parameter.\n",
    "\n",
    "#### Step 5: Spectral Embedding\n",
    "\n",
    "    - The spectral embedding is performed by calling sembedding, which presumably computes the eigenvalues (lamb) and eigenvectors (v) of the diffusion operator constructed from the symmetrized neighbor graph.\n",
    "\n",
    "    - The first few eigenvectors (psi) are normalized and selected as the embedding coordinates. The number of eigenfunctions computed (nEigs) is determined based on the parameter p.num_eigs and the number of samples.\n",
    "\n",
    "#### Step 6: Riemannian Measure\n",
    "\n",
    "    - The Riemannian measure (mu) is calculated from the first eigenvector (v[:, 0]), which corresponds to the stationary distribution of the diffusion process.\n",
    "\n",
    "#### Step 7: Return Statement\n",
    "\n",
    "    - The function returns the computed eigenvalues (lamb), the selected eigenvectors (psi), the Gaussian kernel width (sigma), the Riemannian measure (mu), and additional information related to the autotuning process (logEps, logSumWij, popt, R_squared)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2103382",
   "metadata": {},
   "source": [
    "The DMembeddingIIop function performs diffusion maps embedding and takes several arguments, each playing a specific role in the embedding process. \n",
    "\n",
    "#### D\n",
    "\n",
    "    - Description: The distance matrix for the dataset.\n",
    "    \n",
    "    - Role: It represents the pairwise distances between data points in the dataset. This matrix is fundamental for constructing the affinity (or similarity) matrix that underlies the diffusion map process.\n",
    "\n",
    "#### k\n",
    "\n",
    "    - Description: The number of nearest neighbors to consider for each point in the dataset.\n",
    "     \n",
    "    - Role: It is used to define the local neighborhood around each data point when constructing the affinity matrix from the distance matrix. This parameter controls the sparsity of the affinity matrix and influences the emphasis on local versus global data structure in the resulting embedding.\n",
    "\n",
    "#### tune\n",
    "\n",
    "    - Description: A tuning parameter that might be used to adjust the scale of distances or the width of the Gaussian kernel during the autotuning process.\n",
    "    \n",
    "    - Role: It is involved in fine-tuning the Gaussian kernel width (σ) calculation, thereby affecting the sensitivity of the embedding to features at different scales.\n",
    "\n",
    "#### prefsigma\n",
    "\n",
    "    - Description: A preferred or preset value for the Gaussian kernel width (σ).\n",
    "    \n",
    "    - Role: This value is used as a fallback for the Gaussian kernel width in case the autotuning process does not yield a satisfactory result or is bypassed. It directly influences the decay rate of similarity with distance, impacting the focus of embedding on local versus global structures. The function seems to be structured to perform several key steps of the diffusion map process, including:\n",
    "\n",
    "      - (a) Constructing an affinity matrix from the distance matrix, likely using a Gaussian kernel whose width (σ) is determined through an autotuning process.\n",
    "      \n",
    "      - (b) Performing eigenvalue decomposition on the affinity matrix to obtain eigenvalues (lamb) and eigenvectors (psi), which represent the embedded coordinates.\n",
    "      \n",
    "      - (c) The tune parameter adjusts the autotuning of σ, while prefsigma provides a direct way to specify σ.\n",
    "\n",
    "#### Return values\n",
    "\n",
    "    - The return values (lamb, psi, sigma, mu, logEps, logSumWij, popt, R_squared) include the eigenvalues and eigenvectors essential for understanding the geometry of the data in the embedded space, as well as diagnostic information about the autotuning process and the diffusion characteristics of the diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc26f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DMembeddingIIop(D, k, tune, prefsigma):\n",
    "    \"\"\"\n",
    "    Performs spectral embedding of data points based on their pairwise distances using\n",
    "    the diffusion maps approach. This function initializes the necessary structures,\n",
    "    processes the data to construct a symmetric distance matrix, and performs spectral\n",
    "    decomposition to obtain embedding coordinates. Additionally, it estimates the optimal\n",
    "    sigma for the Gaussian kernel using the Ferguson method.\n",
    "\n",
    "    Parameters:\n",
    "    - D (np.ndarray): A square matrix of pairwise distances between data points.\n",
    "    - k (int): The number of nearest neighbors to consider.\n",
    "    - tune (float): A tuning parameter for adjusting the Gaussian kernel width.\n",
    "    - prefsigma (float): A predefined sigma value for the Gaussian kernel, used if the\n",
    "      tuning process based on the Ferguson method does not converge.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the following elements:\n",
    "        - lamb (np.ndarray): The computed eigenvalues of the Laplacian matrix.\n",
    "        - psi (np.ndarray): The computed eigenvectors of the Laplacian matrix, representing\n",
    "          the embedding coordinates.\n",
    "        - sigma (float): The final sigma value used for the Gaussian kernel.\n",
    "        - mu (np.ndarray): The Riemannian measure derived from the first eigenvector.\n",
    "        - logEps (np.ndarray): The logarithmic epsilon values used in the Ferguson method.\n",
    "        - logSumWij (np.ndarray): The logarithm of the sum of weights for each logEps value.\n",
    "        - popt (np.ndarray): The optimized parameters from the Ferguson curve fitting.\n",
    "        - R_squared (float): The coefficient of determination from the curve fitting.\n",
    "\n",
    "    Notes:\n",
    "    - The function begins by initializing nearest neighbors and constructing a symmetric\n",
    "      distance matrix through batch processing.\n",
    "    - It employs the Ferguson method to estimate the optimal sigma for the Gaussian kernel\n",
    "      based on the distance matrix.\n",
    "    - Spectral decomposition of the Laplacian matrix is performed to obtain the embedding\n",
    "      coordinates (psi) and the eigenvalues (lamb).\n",
    "    - The process includes a fallback to a predefined sigma (prefsigma) if the tuning does\n",
    "      not converge within a specified threshold.\n",
    "    - The Riemannian measure (mu) is calculated as the square of the first eigenvector,\n",
    "      normalized so that its sum equals 1. This measure can be used to weight the embedded\n",
    "      points in further analysis.\n",
    "    \"\"\"\n",
    "    nS = D.shape[0]\n",
    "    nN = k  # Total number of entries is nS*nN\n",
    "    yInd1, yVal1 = initialize(nS, nN, D)\n",
    "\n",
    "    # Diffraction patterns:\n",
    "    nB = nS  # Batch size (number of diff. patterns per batch)\n",
    "    nNIn = k  # Number of input nearest neighbors\n",
    "    nN = k  # Number of output nearest neighbors\n",
    "    yVal = np.zeros((nS * nN, 1))\n",
    "    yCol = np.zeros((nS * nN, 1))\n",
    "    nBatch = int(nS / nB)\n",
    "\n",
    "    for iBatch in range(nBatch):\n",
    "        # Linear indices in the non-symmetric distance matrix (indStart, indEnd)\n",
    "        indStart = iBatch * nB * nN\n",
    "        indEnd = (iBatch + 1) * nB * nN\n",
    "        # Diffraction pattern indices (jStart, jEnd):\n",
    "        jStart = iBatch * nB\n",
    "        jEnd = (iBatch + 1) * nB\n",
    "        params = (yVal, yVal1, yCol, yInd1, nB, nN, nNIn, jStart, jEnd, indStart, indEnd, iBatch)\n",
    "        yCol, yVal = get_yColVal(params)\n",
    "\n",
    "    # Symmetrizing the distance matrix\n",
    "    yRow = np.ones((nN, 1)) * range(nS)\n",
    "    yRow = yRow.reshape(nS * nN, 1)\n",
    "    ifZero = yVal < 1e-6\n",
    "    yRowNZ = yRow[~ifZero]\n",
    "    yColNZ = yCol[~ifZero]\n",
    "    yValNZ = np.sqrt(yVal[~ifZero])\n",
    "    nNZ = len(yRowNZ)  # Number of nonzero elements in the non-sym matrix\n",
    "    yRow = yRow[ifZero]\n",
    "    yCol = yCol[ifZero]\n",
    "    nZ = len(yRow)  # Number of zero elements in the non-sym matrix\n",
    "    y = construct_matrix0(yRowNZ, yColNZ, yValNZ, nZ, nS)\n",
    "    yRowNZ = y.nonzero()[0]\n",
    "    yColNZ = y.nonzero()[1]\n",
    "    yValNZ = y[y.nonzero()]\n",
    "    nNZ = len(y.nonzero()[0]) # Number of nonzero elements in the sym matrix\n",
    "    y = construct_matrix1(yRow, yCol, np.ones((nZ, 1)).flatten(), nZ, nS)\n",
    "    y = csr_matrix((np.ones((nZ, 1)).flatten(), (yRow, yCol)), shape=(nS, nS)).toarray()\n",
    "    yRow = y.nonzero()[0]\n",
    "    yCol = y.nonzero()[1]\n",
    "    yVal = y[y.nonzero()]\n",
    "    yVal[:] = 0\n",
    "    nZ = len(y.nonzero()[0])  #number of zero elements in the sym matrix\n",
    "    yRow = np.hstack((yRow, yRowNZ)).astype(int)\n",
    "    yCol = np.hstack((yCol, yColNZ)).astype(int)\n",
    "    yVal = np.hstack((yVal, yValNZ))\n",
    "    count = 0\n",
    "    resnorm = np.inf\n",
    "    logEps = np.arange(-150, 150.2, 0.2)\n",
    "    popt, logSumWij, resnorm, R_squared = fergusonE(np.sqrt(yVal), logEps)\n",
    "    nS = D.shape[0]\n",
    "    nEigs = min(p.num_eigs, nS - 3)  # Number of eigenfunctions to compute\n",
    "    nA = 0  # Autotuning parameter\n",
    "    nN = k  # Number of nearest neighbors\n",
    "    nNA = 0  # Number of nearest neighbors used for autotuning\n",
    "    if count < 20:\n",
    "        alpha = 1  # Kernel normalization\n",
    "        sigma = tune * np.sqrt(2 * np.exp(-popt[1] / popt[0]))  # Gaussian Kernel width (=1 for autotuning)\n",
    "    else:\n",
    "        print('using prefsigma...')  # Fallback to predefined sigma\n",
    "        sigma = prefsigma\n",
    "        alpha = 1\n",
    "    visual = 1\n",
    "    options = namedtuple('Options', 'sigma alpha visual nEigs')\n",
    "    options.sigma = sigma\n",
    "    options.alpha = alpha\n",
    "    options.visual = visual\n",
    "    options.nEigs = nEigs\n",
    "    lamb, v = sembedding(yVal, yCol, yRow, nS, options)\n",
    "    true_shape = v.shape[1] - 1\n",
    "    psi = np.zeros((v.shape[0], nEigs))\n",
    "    psi[:, :true_shape] = v[:, 1:] / np.tile(v[:, 0].reshape((-1, 1)), (1, true_shape))\n",
    "    mu = v[:, 0]\n",
    "    mu = mu * mu  # The Riemannian measure\n",
    "    return (lamb, psi, sigma, mu, logEps, logSumWij, popt, R_squared)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0d14709",
   "metadata": {},
   "source": [
    "********  DMembeddingII  ********"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9847f5fa",
   "metadata": {},
   "source": [
    "********  manifoldTrimmingAuto  ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psiPath(psi, rad, plotNum):\n",
    "    \"\"\"\n",
    "    Identifies the indices of points in the embedded space within a specified radius from the origin.\n",
    "\n",
    "    Parameters:\n",
    "    - psi (np.ndarray): The matrix of embedded coordinates, where each column represents a dimension.\n",
    "    - rad (float): The radius within which to consider points as being part of the path.\n",
    "    - plotNum (int): The starting dimension in the embedded space for calculating distances.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: An array of indices of points within the specified radius from the origin in the\n",
    "      embedded space defined by the dimensions starting at plotNum.\n",
    "\n",
    "    Notes:\n",
    "    - This function calculates the Euclidean distance from the origin in a 3-dimensional space\n",
    "      defined by the dimensions plotNum, plotNum+1, and plotNum+2 of the embedded coordinates.\n",
    "    - Points with a distance less than 'rad' from the origin are considered part of the path.\n",
    "    \"\"\"\n",
    "    psinum1 = plotNum\n",
    "    psinum2 = plotNum + 1\n",
    "    psinum3 = plotNum + 2\n",
    "    psiDist = np.sqrt(psi[:, psinum1]**2 + psi[:, psinum2]**2 + psi[:, psinum3]**2)\n",
    "    posPathInt = (psiDist < rad).nonzero()[0]\n",
    "    return posPathInt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee369157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_plot(lamb, psi, string):\n",
    "    \"\"\"\n",
    "    Visualizes the eigenvalues and the first four dimensions of the embedded coordinates.\n",
    "\n",
    "    Parameters:\n",
    "    - lamb (np.ndarray): The array of eigenvalues obtained from spectral decomposition.\n",
    "    - psi (np.ndarray): The matrix of embedded coordinates, where each column represents a dimension.\n",
    "    - string (str): The title for the plot.\n",
    "\n",
    "    Notes:\n",
    "    - The function creates a 1x3 subplot:\n",
    "        - The first subplot displays a bar plot of the eigenvalues excluding the first one.\n",
    "        - The second and third subplots show scatter plots of the first four dimensions of the\n",
    "          embedded coordinates, illustrating the distribution of points in the embedded space.\n",
    "    - This visualization helps in understanding the variance captured by each eigenvalue and\n",
    "      the structure of the data in the embedded space.\n",
    "    \"\"\"\n",
    "    f, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(15, 5))  \n",
    "    ax0.bar(range(len(lamb) - 1), lamb[1:], color=\"green\")\n",
    "    ax0.set_title('Eigenvalues') \n",
    "    ax1.scatter(psi[:, 0], psi[:, 1], marker='+', s=30, alpha=0.6)\n",
    "    ax1.set_title('First vs Second Dimension')  \n",
    "    ax2.scatter(psi[:, 2], psi[:, 3], marker='+', s=30, alpha=0.6)\n",
    "    ax2.set_title('Third vs Fourth Dimension')  \n",
    "    f.suptitle(string, fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c86d40",
   "metadata": {},
   "source": [
    "### manifoldTrimmingAutoop function\n",
    "\n",
    "The manifoldTrimmingAutoop function performs manifold trimmin and embedding operation on a given dataset, focusing on identifying and preserving the intrinsic geometric structure of the data.      \n",
    "\n",
    "#### Example Scenario\n",
    "\n",
    "Imagine we have a dataset representing a collection of high-dimensional data points, such as images or sensor readings, that we suspect lies on or near a lower-dimensional manifold. Our goal is to analyze this dataset to understand its underlying structure, reduce its dimensionality, and potentially remove outliers or noise.\n",
    "\n",
    "#### Function Breakdown\n",
    "\n",
    "#### (A) Input Parameters\n",
    "\n",
    "    1. input_data: A list containing paths or identifiers for the distance matrix file (dist_file), the file to save psi values (psi_file), and the file to save eigenvalues (eig_file), along with an identifier (prD) for the current processing dataset.\n",
    "\n",
    "    2. posPath: Initial positions or indices of data points to consider. If set to 0, it implies all points are considered initially.\n",
    "\n",
    "    3. tune: A tuning parameter used in the manifold analysis process.\n",
    "\n",
    "    4. rad: A radius parameter used to determine which points are kept during the trimming process.\n",
    "\n",
    "    5. visual: A boolean indicating whether to visually display the results.\n",
    "    \n",
    "    6. doSave: A dictionary indicating whether and where to save the results.\n",
    "\n",
    "#### (B) Process\n",
    "\n",
    "    1. The function begins by loading the distance matrix D from dist_file, which represents the pairwise distances between data points in the dataset. If posPath is 0, it initializes posPath to include all indices in the dataset. The distance matrix D is then filtered to only include distances between points specified by posPath, effectively focusing the analysis on a subset of the data.\n",
    "\n",
    "    2. The function calls DMembeddingIIop with the filtered distance matrix, the number of points k, the tuning parameter, and a fixed sigma value. This operation is aimed at embedding the data points into a lower-dimensional space while preserving their geometric relationships.\n",
    "\n",
    "    3. The result includes eigenvalues (lamb), eigenvectors (psi), and other metrics that describe the structure of th manifold. The function then identifies points within a specified radius (rad) from the center of the manifold using get_psiPath and iteratively refines the dataset by focusing on these points, potentially removing outliers or noise.\n",
    "\n",
    "    4. If visual is True, it visualizes the eigenvalues and the embedded points at each iteration. Once the process converges or completes, it updates posPath to reflect the final set of points considered part of the manifold.\n",
    "\n",
    "#### (C) Output\n",
    "\n",
    "    If doSave['Is'] is True, it saves the analysis results, including eigenvalues, eigenvectors, and other metrics, to the specified psi_file. It also writes the eigenvalues to eig_file, providing a summary of the dimensional structure of the manifold.\n",
    "    \n",
    "#### (D) What is Saved \n",
    "\n",
    "    1. Eigenvalue File (eig_file): This file saves the eigenvalues (lamb) obtained from the diffusion maps embedding (DMembeddingIIop). Each line in the file contains an index (starting from 1) and the corresponding eigenvalue, separated by a tab. The eigenvalues represent the spectrum of the diffusion operator, providing insight into the intrinsic geometric structure of the data.\n",
    "\n",
    "    2. Psi File (psi_file): The psi file is saved using the fout1 function. Based on the context, this file includes the eigenvectors (psi), along with other related outputs such as the eigenvalues (lamb), the scaling factor (sigma), the mean vector (mu), the path taken through the manifold (posPath), indices (ind), parameters related to the embedding (logEps, logSumWij, popt, R_squared). These components are critical for understanding and visualizing the manifold structure and the data distribution within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72e6765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manifoldTrimmingAutoop(input_data, posPath, tune, rad, visual, doSave):\n",
    "    \"\"\"\n",
    "    Performs manifold learning and trimming based on spectral embedding, iteratively refining\n",
    "    the embedding by trimming points outside a specified radius.\n",
    "\n",
    "    Parameters:\n",
    "    - input_data (list): A list containing paths to input files and additional parameters.\n",
    "        - dist_file (str): Path to the file containing the distance matrix.\n",
    "        - psi_file (str): Path to the file where the psi (embedding coordinates) will be saved.\n",
    "        - eig_file (str): Path to the file where the eigenvalues will be saved.\n",
    "        - prD (int): An identifier for the current processing dataset.\n",
    "    - posPath (int or np.ndarray): Initial positions/path of points to consider. If 0, all points are considered.\n",
    "    - tune (float): A tuning parameter for adjusting the Gaussian kernel width in the embedding process.\n",
    "    - rad (float): The radius within which points are considered part of the manifold.\n",
    "    - visual (bool): A flag indicating whether to visualize the embedding and trimming process.\n",
    "    - doSave (dict): A dictionary indicating whether to save the results ('Is' key) and the output file path.\n",
    "\n",
    "    Notes:\n",
    "    - The function starts by loading the distance matrix and optionally filters it based on `posPath`.\n",
    "    - It then performs spectral embedding using `DMembeddingIIop` and trims points outside the specified `rad`.\n",
    "    - This process is repeated until the set of points within the radius no longer changes significantly.\n",
    "    - Visualization of the embedding before and after trimming is optional and controlled by the `visual` flag.\n",
    "    - Results, including the final set of points, embedding coordinates, and eigenvalues, can be saved to files.\n",
    "    \"\"\"\n",
    "    # Load distance matrix and initial positions\n",
    "    dist_file = input_data[0]\n",
    "    psi_file = input_data[1]\n",
    "    eig_file = input_data[2]\n",
    "    prD = input_data[3]\n",
    "    data = fin1(dist_file)\n",
    "    D = data['D']\n",
    "    ind = data['ind']\n",
    "    nS = D.shape[1]\n",
    "\n",
    "    # Initialize or filter positions\n",
    "    if posPath == 0:\n",
    "        posPath = np.arange(nS)\n",
    "    D = D[posPath][:, posPath]\n",
    "    nS = D.shape[1]\n",
    "    k = nS\n",
    "\n",
    "    # Perform initial spectral embedding\n",
    "    lamb, psi, sigma, mu, logEps, logSumWij, popt, R_squared = DMembeddingIIop(D, k, tune, 60000)\n",
    "\n",
    "    # Trim the manifold based on the specified radius\n",
    "    posPath1 = get_psiPath(psi, rad, 0)\n",
    "    cc = 0\n",
    "    while len(posPath1) < nS:\n",
    "        cc += 1\n",
    "        nS = len(posPath1)\n",
    "        D1 = D[posPath1][:, posPath1]\n",
    "        k = D1.shape[0]\n",
    "        lamb, psi, sigma, mu, logEps, logSumWij, popt, R_squared = DMembeddingIIop(D1, k, tune, 600000)\n",
    "\n",
    "        # Update positions based on trimming\n",
    "        posPathInt = get_psiPath(psi, rad, 0)\n",
    "        posPath1 = posPath1[posPathInt]\n",
    "\n",
    "        # Optional visualization\n",
    "        if visual:\n",
    "            show_plot(lamb, psi, 'in loop')\n",
    "\n",
    "    # Final visualization\n",
    "    if visual:\n",
    "        show_plot(lamb, psi, 'out loop')\n",
    "\n",
    "    # Update positions and optionally save results\n",
    "    posPath = posPath[posPath1]\n",
    "    if doSave['Is']:\n",
    "        fout1(psi_file, lamb=lamb, psi=psi, sigma=sigma, mu=mu, posPath=posPath, ind=ind,\n",
    "              logEps=logEps, logSumWij=logSumWij, popt=popt, R_squared=R_squared)\n",
    "    \n",
    "    # Save eigenvalues\n",
    "    with open(eig_file, \"w\") as file:\n",
    "        for i in range(1, len(lamb)):\n",
    "            file.write(\"%d\\t%.5f\\n\" % (i, lamb[i]))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3b142ad2",
   "metadata": {},
   "source": [
    "********  manifoldTrimmingAuto  ********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _construct_input_data(N):\n",
    "    \"\"\"\n",
    "    Constructs a list of input data configurations for multiple datasets.\n",
    "\n",
    "    Parameters:\n",
    "    - N (int): The number of datasets to generate configurations for.\n",
    "\n",
    "    Returns:\n",
    "    - list: A list where each element is a list containing paths to the distance matrix file,\n",
    "      psi file, and eigenvalue file for a dataset, along with the dataset's identifier (prD).\n",
    "\n",
    "    Notes:\n",
    "    - This function assumes the existence of a global variable `p` that provides methods\n",
    "      `get_dist_file` and `get_psi_file`, and an attribute `out_dir` to determine the paths\n",
    "      to the distance matrix, psi files, and the output directory for eigenvalue files,\n",
    "      respectively.\n",
    "    - Each dataset is assigned a unique identifier `prD` (ranging from 0 to N-1), which is\n",
    "      used to generate file paths and included in the output configuration for reference.\n",
    "    - The eigenvalue file path is constructed using a template that includes the output\n",
    "      directory and the dataset identifier, assuming a specific directory structure.\n",
    "    \"\"\"\n",
    "    ll = []\n",
    "    for prD in range(N):\n",
    "        # Generate file paths for the distance matrix, psi, and eigenvalues\n",
    "        dist_file = p.get_dist_file(prD)\n",
    "        psi_file = p.get_psi_file(prD)\n",
    "        eig_file = '{}/topos/PrD_{}/eig_spec.txt'.format(p.out_dir, prD + 1)\n",
    "\n",
    "        # Append the configuration for this dataset to the list\n",
    "        ll.append([dist_file, psi_file, eig_file, prD])\n",
    "    \n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddee79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def op(*argv):\n",
    "    \"\"\"\n",
    "    Orchestrates the processing of multiple datasets for manifold learning and trimming,\n",
    "    utilizing multiprocessing for parallel execution.\n",
    "\n",
    "    Parameters:\n",
    "    - *argv: Variable length argument list. If provided, the first argument is expected to\n",
    "      be an object capable of emitting progress updates (e.g., a GUI progress bar emitter).\n",
    "      If no arguments are provided, a NullEmitter is used which does not perform any action\n",
    "      on progress updates.\n",
    "\n",
    "    Notes:\n",
    "    - The function begins by loading configuration parameters using `p.load()`.\n",
    "    - It sets the multiprocessing start method to 'fork' to optimize for certain environments.\n",
    "    - The presence of any arguments in `argv` indicates the use of a GUI progress emitter.\n",
    "    - It constructs input data configurations for each dataset using `_construct_input_data`.\n",
    "    - Depending on the number of CPUs specified in the configuration (`p.ncpu`), it either\n",
    "      processes the datasets sequentially or in parallel using a multiprocessing pool.\n",
    "    - Progress updates are emitted based on the processing state, with a final update to\n",
    "      indicate completion.\n",
    "    - Configuration parameters are saved after processing using `p.save()`.\n",
    "    \"\"\"\n",
    "    print(\"Computing the eigenfunctions...\")\n",
    "    p.load()  # Load configuration parameters\n",
    "    multiprocessing.set_start_method('fork', force=True)  # Optimize multiprocessing start method\n",
    "\n",
    "    use_gui_progress = len(argv) > 0  # Determine if GUI progress emitter is used\n",
    "    input_data = _construct_input_data(p.numberofJobs)  # Construct input data configurations\n",
    "    n_jobs = len(input_data)  # Determine the number of jobs based on input data\n",
    "    progress2 = argv[0] if use_gui_progress else NullEmitter()  # Initialize progress emitter\n",
    "\n",
    "    # Create necessary subdirectories for output\n",
    "    for i in range(n_jobs):\n",
    "        subdir = os.path.join(p.out_dir, 'topos', f'PrD_{i+1}')\n",
    "        os.makedirs(subdir, exist_ok=True)\n",
    "\n",
    "    # Define the local trimming function with fixed parameters\n",
    "    local_trim_func = partial(manifoldTrimmingAutoop,\n",
    "                              posPath=0,\n",
    "                              tune=p.tune,\n",
    "                              rad=p.rad,\n",
    "                              visual=False,\n",
    "                              doSave=dict(outputFile='', Is=True))\n",
    "\n",
    "    # Process datasets either sequentially or in parallel\n",
    "    if p.ncpu == 1:\n",
    "        # Sequential processing\n",
    "        for i, datai in tqdm.tqdm(enumerate(input_data), total=n_jobs, disable=use_gui_progress):\n",
    "            local_trim_func(datai)\n",
    "            progress2.emit(int(99 * i / n_jobs))  # Emit progress update\n",
    "    else:\n",
    "        # Parallel processing using multiprocessing pool\n",
    "        with multiprocessing.Pool(processes=p.ncpu) as pool:\n",
    "            for i, _ in tqdm.tqdm(enumerate(pool.imap_unordered(local_trim_func, input_data)),\n",
    "                                  total=n_jobs,\n",
    "                                  disable=use_gui_progress):\n",
    "                progress2.emit(int(99 * i / n_jobs))  # Emit progress update\n",
    "\n",
    "    p.save()  # Save configuration parameters after processing\n",
    "    progress2.emit(100)  # Emit final progress update indicating completion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4bf34058",
   "metadata": {},
   "source": [
    "op()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fe7ed9",
   "metadata": {},
   "source": [
    "### Step 1: Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.load()\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e91fff",
   "metadata": {},
   "source": [
    "### Step 2: Construct Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding and trimming manifold from particles\n",
    "input_data = _construct_input_data(p.numberofJobs)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79bd77",
   "metadata": {},
   "source": [
    "### Step 3: Define the Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f89820",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = len(input_data)\n",
    "for i in range(n_jobs):\n",
    "    subdir = os.path.join(p.out_dir, 'topos', f'PrD_{i+1}')\n",
    "    os.makedirs(subdir, exist_ok=True)\n",
    "local_trim_func = partial(manifoldTrimmingAutoop,posPath=0,tune=p.tune,rad=p.rad,\n",
    "                          visual=False,doSave=dict(outputFile='', Is=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299716ea",
   "metadata": {},
   "source": [
    "### Step 4: Process Datasets Sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e972d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, datai in tqdm.tqdm(enumerate(input_data), total=n_jobs):\n",
    "    local_trim_func(datai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12c9aab",
   "metadata": {},
   "source": [
    "### Step 5: Save Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdcc2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9666d1",
   "metadata": {},
   "source": [
    "### Simplified Diffusion Map Embedding Example\n",
    "\n",
    "Let us construct a simplified example that demonstrates the essence of diffusion map embedding using synthetic data. This example will highlight the process of creating a distance matrix, performing diffusion map embedding, and visualizing the results. For simplicity, we will implement a basic version of diffusion map embedding without the autotuning of σ and other features present in the DMembeddingIIop function. We will generate a two-dimensional dataset arranged in an \"S\" shape, compute its distance matrix, apply a basic diffusion map embedding, and visualize the embedding. \n",
    "\n",
    "    1. Data Generation: We will generate synthetic data arranged in an \"S\" shape using make_s_curve. This provides a simple yet non-linearly separable dataset suitable for demonstrating manifold learning.\n",
    "\n",
    "    2. Distance Matrix: We will then compute the pairwise distance matrix \"D\" of the dataset using pairwise_distances.\n",
    "\n",
    "    3. Affinity Matrix: We will now construct the affinity matrix \"A\" using a Gaussian kernel, where sigma controls the kernel width. This matrix represents the similarity between points based on their distances.\n",
    "\n",
    "    4. Row Normalization: We now normalize \"A\" row-wise to obtain the transition probability matrix \"P\", which is used in the diffusion process.\n",
    "\n",
    "    5. Eigenvalue Decomposition: We perform an eigenvalue decomposition on \"P\" to extract the eigenvalues and eigenvectors. The eigenvectors corresponding to the largest eigenvalues (excluding the trivial solution) serve as the embedding coordinates.\n",
    "\n",
    "    6. Visualization: We plot the first two non-trivial eigenvectors (psi_1 and psi_2) against each other to visualize the embedded data points. This visualization reveals the intrinsic geometry of the data as captured by the diffusion map.\n",
    "\n",
    "Note: This example provides a basic illustration of diffusion map embedding. The actual DMembeddingIIop function includes more sophisticated steps, such as autotuning σ and handling sparse matrices for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e60c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the \"S\" shaped dataset\n",
    "X, color = make_s_curve(1000, random_state=42)\n",
    "# Compute the pairwise distance matrix\n",
    "D = pairwise_distances(X)\n",
    "# Compute the affinity matrix using Gaussian kernel\n",
    "sigma = 1.0  # Gaussian kernel width\n",
    "A = np.exp(-D**2 / (2. * sigma**2))\n",
    "# Row normalization\n",
    "row_sums = A.sum(axis=1)\n",
    "P = A / row_sums[:, np.newaxis]\n",
    "# Eigenvalue decomposition for diffusion map embedding\n",
    "# Update to use 'subset_by_index' instead of 'eigvals'\n",
    "eigenvalues, eigenvectors = eigh(P, subset_by_index=[P.shape[0]-3, P.shape[0]-2])\n",
    "# Normalize the eigenvectors to use as embedding coordinates\n",
    "psi_1 = eigenvectors[:, 1] / np.sqrt(eigenvalues[1])\n",
    "psi_2 = eigenvectors[:, 0] / np.sqrt(eigenvalues[0])\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "# Original \"S\" shaped dataset\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)\n",
    "ax.set_title('Original \"S\" Shaped Dataset')\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "# Diffusion map embedding\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "scatter = ax2.scatter(psi_1, psi_2, c=color, cmap=plt.cm.Spectral)\n",
    "ax2.set_title('Diffusion Map Embedding')\n",
    "ax2.set_xlabel('Psi_1')\n",
    "ax2.set_ylabel('Psi_2')\n",
    "plt.colorbar(scatter, ax=ax2, label='Color Mapping')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a262362",
   "metadata": {},
   "source": [
    "## Illustration of the steps involved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241254df",
   "metadata": {},
   "source": [
    "### Step 1:  Load Distance Matrix  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af45c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take one of the prDs for analyis among all the prDs by input_data[i]\n",
    "# In this case, we select the projection direction 2\n",
    "n=2\n",
    "input_data_sample = input_data[n]\n",
    "prD_file = open(input_data_sample[0], 'rb')\n",
    "data_from_prD = pickle.load(prD_file)\n",
    "print(data_from_prD.keys())\n",
    "distance_matrix = data_from_prD['D']\n",
    "print(\"Shape of the Distance Matrix\")\n",
    "print(distance_matrix.shape)\n",
    "print(\"Distance Matrix from one of the projection Directions\")\n",
    "print(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacb5b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the distance matrix\n",
    "sns.heatmap(distance_matrix, cmap='viridis', square=True)\n",
    "plt.title('Heatmap of the Distance Matrix')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9d63f1",
   "metadata": {},
   "source": [
    "### Step 2:  Perform initial spectral embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfc3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2A: Find the nearest neighbors for the DMembedding function \n",
    "nS = distance_matrix.shape[1]\n",
    "k = nS\n",
    "print(\"Nearest neighbors :\", k)\n",
    "\n",
    "# Step 2B: Assign prefsigma and tune values\n",
    "prefsigma = 60000\n",
    "tune = p.tune\n",
    "print(\"prefsigma:\", prefsigma)\n",
    "print(\"tune:\", tune)\n",
    "\n",
    "# Step 2C: Perform Diffusion Map Embedding\n",
    "lamb, psi, sigma, mu, logEps, logSumWij, popt, R_squared = DMembeddingIIop(distance_matrix, k, tune, prefsigma)\n",
    "print(\"Initial spectral embedding performed.\")\n",
    "print(\"The shape of psi is\", psi.shape)\n",
    "print(\"The shape of lamb is\", lamb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64268948",
   "metadata": {},
   "source": [
    "### Step 3: Trim the manifold based on the specified radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ee7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rad = p.rad\n",
    "print(\"The trimming radius is\", rad)\n",
    "posPath1 = get_psiPath(psi, rad, 0)\n",
    "print(\"The length of posPath1 is\", len(posPath1))\n",
    "cc = 0\n",
    "while len(posPath1) < nS:\n",
    "    cc += 1\n",
    "    nS = len(posPath1)\n",
    "    D1 = D[posPath1][:, posPath1]\n",
    "    k = D1.shape[0]\n",
    "    lamb, psi, sigma, mu, logEps, logSumWij, popt, R_squared = DMembeddingIIop(D1, k, tune, prefsigma)\n",
    "print(\"The trimmed distance matrix is of shape\", D1.shape)\n",
    "print(\"The shape of psi is\", psi.shape)\n",
    "print(\"The length of lamb is\", len(lamb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d54a03e",
   "metadata": {},
   "source": [
    "### Step 4: Update positions based on manifold trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0a58af",
   "metadata": {},
   "outputs": [],
   "source": [
    "posPathInt = get_psiPath(psi, rad, 0)\n",
    "posPath1 = posPath1[posPathInt]\n",
    "print(posPath1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507c85c",
   "metadata": {},
   "source": [
    "### Step 5: Visualize the eigenvalues and the first four dimensions of the embedded coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9819cc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_plot(lamb, psi, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bcf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first two principal components\n",
    "plt.scatter(psi[:, 0], psi[:, 1], c='red', alpha=0.5)\n",
    "plt.title('Diffusion Map Embedding (PC1 and PC2)')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.colorbar(label='Point index')\n",
    "plt.show()\n",
    "\n",
    "# Plot the next two principal components\n",
    "plt.scatter(psi[:, 2], psi[:, 3], c='red', alpha=0.5)\n",
    "plt.title('Diffusion Map Embedding (PC3 and PC4)')\n",
    "plt.xlabel('Component 1')\n",
    "plt.ylabel('Component 2')\n",
    "plt.colorbar(label='Point index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef847c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the eigen values\n",
    "plt.figure()\n",
    "plt.plot(lamb, marker='o', color='black')  \n",
    "plt.title('Eigenvalues (Scree Plot)')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Eigenvalue')\n",
    "plt.grid(False) \n",
    "plt.show()\n",
    "\n",
    "# Plotting the  Riemannian Measure\n",
    "plt.figure()\n",
    "plt.plot(mu, marker='o', linestyle='-', color='green')\n",
    "plt.title('Riemannian Measure (mu)')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Measure Value')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
