{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136c91bb",
   "metadata": {},
   "source": [
    "## Overview of the Projection Direction Calculations\n",
    "The process involves organizing the orientation data (represented as quaternions) into bins based on their distribution on the unit sphere (S2). This binning helps identify clusters of similar orientations that correspond to similar projection directions. After thresholding, the number of significant bins effectively represents the number of distinct projection directions captured in the dataset.\n",
    "## Steps\n",
    "\n",
    "### Augmentation with Conjugate Quaternions\n",
    "The dataset is augmented by adding the conjugate of each quaternion. This step ensures coverage of the entire orientation space by including both orientations and their inverses.\n",
    "### Mapping to S2 Coordinates\n",
    "Quaternions are mapped to points on the unit sphere (S2) using a mapping function. This function translates the 4D quaternion data into 3D points, each representing a unique orientation in space.\n",
    "### Binning on the Unit Sphere (S2)\n",
    "The points on S2 are organized into bins or clusters using the bin_and_threshold function. This function groups points close to each other on the sphere, with each bin representing a cluster of similar orientations (or projection directions).\n",
    "### Thresholding Bins\n",
    "Not all bins are equally significant. Some may need more points to be considered reliable representations of a projection direction. A bin cum threshold function applies lower and upper thresholds to filter out bins based on the number of points they contain. Only bins with a point count within the specified range are kept for further analysis.\n",
    "### Determining the Number of Projection Directions\n",
    "After binning and thresholding, the remaining bins represent the significant projection directions in the dataset. These bins directly correspond to the number of distinct projection directions identified. This is captured in the conjugate_bins list, which contains the indices of bins that meet the threshold criteria.\n",
    "### Visualization and Analysis\n",
    "The distribution of bins (and thus projection directions) on S2 can be visualized to assess the coverage and diversity of orientations in the dataset. This step is crucial for ensuring that the dataset adequately samples the orientation space, essential for accurate 3D reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3a5201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Import libraries\n",
    "from scipy.ndimage import affine_transform, map_coordinates, rotate\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from nptyping import NDArray, Shape, Int, Int64, Float64\n",
    "from scipy.fftpack import ifftshift, fft2, ifft2\n",
    "from typing import List, Any, Tuple, Dict, Set\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from dataclasses import dataclass\n",
    "from scipy.ndimage import shift\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from numpy import cos, sin\n",
    "from scipy import optimize\n",
    "import matplotlib.cm as cm\n",
    "from typing import Tuple\n",
    "import multiprocessing\n",
    "from enum import Enum\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import mrcfile\n",
    "import pickle\n",
    "import numba\n",
    "import math\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "# Import Python scripts\n",
    "from params import p\n",
    "from FindCCGraph import op as FindCCGraph\n",
    "project_name = \"sample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e727a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distribute3Sphere(numPts: int):\n",
    "    \"\"\"\n",
    "    Distributes points roughly uniformly on a unit 3-sphere.\n",
    "\n",
    "    Parameters:\n",
    "    - numPts (int): The number of points to distribute on the 3-sphere.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing:\n",
    "        - results (np.ndarray): An array of shape (numPts, 3) containing the coordinates\n",
    "          of the points distributed on the 3-sphere.\n",
    "        - it (int): The number of iterations the algorithm performed.\n",
    "\n",
    "    Notes:\n",
    "    - The algorithm aims for a uniform distribution by adjusting the spacing between points\n",
    "      based on the surface area of a unit 3-sphere and the desired number of points.\n",
    "    - It iteratively adjusts the spacing (delta) to approach the target number of points,\n",
    "      recalculating the distribution in each iteration until the desired number is reached\n",
    "      or the maximum number of iterations (maxIter) is exceeded.\n",
    "    - The algorithm may produce slightly more or fewer points than requested due to the\n",
    "      discretization process. The final number of points returned matches `numPts`.\n",
    "    - This method is useful for generating points for applications requiring uniform\n",
    "      coverage of a spherical surface, such as sampling, simulations, or geometric analyses.\n",
    "    \"\"\"\n",
    "    maxIter = 100  # Maximum number of iterations to attempt\n",
    "    K = numPts\n",
    "    A3 = 4 * np.pi  # Surface area of a unit 3-sphere\n",
    "    delta = np.exp(np.log(A3 / K) / 2.)  # Initial spacing between points\n",
    "    results = np.zeros((2 * K, 3))  # Allocate space for up to twice the requested points\n",
    "    it = 0  # Iteration counter\n",
    "    id = 0  # Point counter\n",
    "\n",
    "    while id != K and it < maxIter:\n",
    "        it += 1\n",
    "        id = 0\n",
    "        dw1 = delta\n",
    "        for w1 in np.arange(0.5 * dw1, np.pi, dw1):\n",
    "            cw1 = np.cos(w1)\n",
    "            sw1 = np.sin(w1)\n",
    "            x1 = cw1\n",
    "            dw2 = dw1 / sw1  # Adjust spacing for the next dimension\n",
    "            for w2 in np.arange(0.5 * dw2, 2 * np.pi, dw2):\n",
    "                cw2 = np.cos(w2)\n",
    "                sw2 = np.sin(w2)\n",
    "                x2 = sw1 * cw2\n",
    "                x3 = sw1 * sw2\n",
    "                if id < 2 * K:  # Prevent index out of bounds\n",
    "                    results[id, :] = np.hstack((x1, x2, x3))\n",
    "                    id += 1\n",
    "        delta = delta * np.exp(np.log(float(id) / K) / 2.)  # Adjust spacing based on current point count\n",
    "\n",
    "    results = results[0:K, :]  # Trim or expand the results to the requested number of points\n",
    "    return (results, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_to_S2(q):\n",
    "    \"\"\"\n",
    "    Converts a set of quaternions to points on the 2-sphere (S2) in three-dimensional space.\n",
    "\n",
    "    This function transforms quaternions, representing rotations in 3D space, into coordinates\n",
    "    on a unit sphere. It effectively captures the orientation encoded by the quaternion while\n",
    "    disregarding the rotation around the final axis (psi rotation), simplifying the representation\n",
    "    of orientation.\n",
    "\n",
    "    Parameters:\n",
    "    - q (np.ndarray): A 4xN numpy array where each column represents a quaternion. The quaternion\n",
    "      is expected to be in the form [q0, q1, q2, q3] with q0 as the real part and q1, q2, q3 as\n",
    "      the imaginary parts.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A 3xN numpy array where each column represents the 3D coordinates [x, y, z] of\n",
    "      a point on the unit sphere (S2). These coordinates correspond to the orientation represented\n",
    "      by the input quaternions.\n",
    "\n",
    "    Notes:\n",
    "    - The conversion formula used in this function maps the quaternion's rotation to a point on\n",
    "      the sphere by selecting specific combinations of the quaternion components. This mapping\n",
    "      focuses on the spatial orientation and ignores the final rotation around the axis, which\n",
    "      is not represented on the 2-sphere.\n",
    "    - The function is useful in contexts where the orientation needs to be visualized or analyzed\n",
    "      without the complexity of handling full quaternion rotations, such as in computer graphics,\n",
    "      robotics, and orientation tracking.\n",
    "    \"\"\"\n",
    "    # Calculate the 3D coordinates on the unit sphere from the quaternion components\n",
    "    S2 = 2*np.vstack((q[1, :]*q[3, :] - q[0, :]*q[2, :],\n",
    "                      q[0, :]*q[1, :] + q[2, :]*q[3, :],\n",
    "                      q[0, :]**2 + q[3, :]**2 - 0.5))\n",
    "    return S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43aac1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_nearest_neighbors(X, Q):\n",
    "    \"\"\"\n",
    "    Finds the nearest neighbors of a set of query points Q within a dataset X and counts\n",
    "    the occurrences of each point in X being the nearest neighbor.\n",
    "\n",
    "    Parameters:\n",
    "    - X (np.ndarray): An array of shape (n_samples, n_features) representing the dataset\n",
    "      within which to search for nearest neighbors. Each row corresponds to a data point.\n",
    "    - Q (np.ndarray): An array of shape (n_queries, n_features) representing the query\n",
    "      points for which the nearest neighbors in X are to be found. Each row corresponds\n",
    "      to a query point.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing:\n",
    "        - neighb_bins (np.ndarray): An array of indices of the nearest neighbors in X for\n",
    "          each query point in Q. Shape is (n_queries, 1).\n",
    "        - bin_counts (np.ndarray): An array of counts indicating how many times each point\n",
    "          in X is the nearest neighbor to the points in Q. Shape is (n_samples,).\n",
    "\n",
    "    Notes:\n",
    "    - The function uses the 'ball_tree' algorithm for efficient nearest neighbor search,\n",
    "      which is particularly suitable for datasets with a large number of samples and/or\n",
    "      high dimensionality.\n",
    "    - The `NearestNeighbors` class from scikit-learn is used to fit the model on dataset X\n",
    "      and then query the nearest neighbors for points in Q.\n",
    "    - The `bin_counts` array provides a histogram-like count of nearest neighbor occurrences,\n",
    "      which can be useful for understanding the density or distribution of query points around\n",
    "      the dataset X.\n",
    "    \"\"\"\n",
    "    nbins = X.shape[0]  # Number of bins is equal to the number of samples in X\n",
    "    nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(X)  # Fit the model on X\n",
    "    neighb_bins = nbrs.kneighbors(Q, return_distance=False)  # Find nearest neighbors for Q in X\n",
    "    bin_counts = np.bincount(neighb_bins.squeeze(), minlength=nbins)  # Count occurrences\n",
    "    return neighb_bins, bin_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f720292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_and_threshold(q, bin_width, thres_low, thres_high):\n",
    "    \"\"\"\n",
    "    Bins quaternions onto a unit sphere and identifies bins based on threshold criteria.\n",
    "\n",
    "    Parameters:\n",
    "    - q (np.ndarray): An array of quaternions to be processed. Expected shape is (4, N),\n",
    "      where N is the number of quaternions.\n",
    "    - bin_width (float): The approximate width of each bin on the sphere, used to calculate\n",
    "      the number of bins based on the surface area of the unit sphere.\n",
    "    - thres_low (int): The lower threshold for the number of points in a bin to be considered\n",
    "      significant.\n",
    "    - thres_high (int): The upper threshold for filtering bins (not directly used in this\n",
    "      function but included for completeness and potential extension).\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing:\n",
    "        - neighb_list (np.ndarray): An array of lists, where each list contains indices of\n",
    "          points in S2 that fall into the corresponding bin.\n",
    "        - S2 (np.ndarray): The coordinates of points on the unit sphere (S2) obtained from\n",
    "          the input quaternions.\n",
    "        - bin_centers (np.ndarray): The coordinates of the centers of the bins on S2.\n",
    "        - n_points_in_bin (np.ndarray): The number of points in each bin.\n",
    "        - conjugate_bins (list): Indices of bins that have more than `thres_low` points and\n",
    "          are in the bigger half of the bin list.\n",
    "\n",
    "    Notes:\n",
    "    - The function first calculates the number of bins based on the specified `bin_width` and\n",
    "      uses the `distribute3Sphere` function to determine the centers of these bins on the unit\n",
    "      sphere.\n",
    "    - It then maps the input quaternions onto the unit sphere (S2) using the `quaternion_to_S2`\n",
    "      function.\n",
    "    - The `collect_nearest_neighbors` function is used to assign each point on S2 to the nearest\n",
    "      bin and count the number of points in each bin.\n",
    "    - Bins are filtered based on the `thres_low` criterion and their position in the bin list to\n",
    "      identify `conjugate_bins` that meet the specified conditions.\n",
    "    - The `thres_high` parameter is included for potential use in extending the function's\n",
    "      functionality but is not used in the current implementation.\n",
    "    \"\"\"\n",
    "    # Attempt to bin sphere in equal patches with area ~bin_width^2\n",
    "    requested_n_bins = int(4 * np.pi / (bin_width**2))\n",
    "    bin_centers = distribute3Sphere(requested_n_bins)[0].T\n",
    "    n_bins = bin_centers.shape[1]\n",
    "\n",
    "    # Map quaternions onto unit_vectors (S2)\n",
    "    S2 = quaternion_to_S2(q)\n",
    "\n",
    "    # For each point in S2, find closest bin\n",
    "    neighb_bins, n_points_in_bin = collect_nearest_neighbors(bin_centers.T, S2.T)\n",
    "\n",
    "    # For each bin, list all points in S2 that live in that bin\n",
    "    neighb_list = [[] for _ in range(n_bins)]\n",
    "    for i, index in enumerate(neighb_bins.ravel()):\n",
    "        neighb_list[index].append(i)\n",
    "    neighb_list = np.array([np.array(a) for a in neighb_list], dtype=object)\n",
    "\n",
    "    # List bins that have more than thres_low points and lie on bigger half of bin list\n",
    "    conjugate_bins = []\n",
    "    start_bin, end_bin = (n_bins // 2, n_bins) if n_bins % 2 else (0, n_bins // 2)\n",
    "    for pd_rel, n_points in enumerate(n_points_in_bin[start_bin:end_bin]):\n",
    "        if n_points >= thres_low:\n",
    "            conjugate_bins.append(pd_rel + start_bin)\n",
    "\n",
    "    return (neighb_list, S2, bin_centers, n_points_in_bin, conjugate_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8bdc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_product(q, s):\n",
    "    \"\"\"\n",
    "    Calculates the quaternion product of two quaternions or arrays of quaternions.\n",
    "\n",
    "    Parameters:\n",
    "    - q (np.ndarray): A 4xN or 4x1 numpy array representing the first quaternion(s),\n",
    "      where N is the number of quaternions.\n",
    "    - s (np.ndarray): A 4xN or 4x1 numpy array representing the second quaternion(s),\n",
    "      matching the dimensions of q.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The quaternion product, in the same format as the inputs (4xN or 4x1).\n",
    "\n",
    "    Notes:\n",
    "    - Quaternions are represented as [q0, q1, q2, q3], where q0 is the scalar part,\n",
    "      and [q1, q2, q3] represent the vector part.\n",
    "    - The function supports broadcasting, allowing for the multiplication of a single\n",
    "      quaternion with an array of quaternions and vice versa.\n",
    "    - Quaternion multiplication is not commutative; the order of operands affects the result.\n",
    "    - This function reshapes 1-dimensional input arrays to 2D for consistent processing\n",
    "      and uses assertions to ensure proper input dimensions.\n",
    "    \"\"\"\n",
    "    # Ensure inputs are 2-dimensional\n",
    "    if len(q.shape) < 2:\n",
    "        q = q.reshape(-1, 1)\n",
    "    if len(s.shape) < 2:\n",
    "        s = s.reshape(-1, 1)\n",
    "\n",
    "    # Check that both quaternions have 4 elements\n",
    "    try:\n",
    "        assert (q.shape[0] > 3 and s.shape[0] > 3)\n",
    "    except AssertionError:\n",
    "        print('subroutine qMult_bsx: some vector have less than 4 elements')\n",
    "\n",
    "    # Decompose quaternions into scalar and vector parts\n",
    "    q0 = q[0, :]\n",
    "    qv = q[1:4, :]\n",
    "    s0 = s[0, :]\n",
    "    sv = s[1:4, :]\n",
    "\n",
    "    # Compute the vector cross product and the quaternion product\n",
    "    c = np.vstack((qv[1, :] * sv[2, :] - qv[2, :] * sv[1, :],\n",
    "                   qv[2, :] * sv[0, :] - qv[0, :] * sv[2, :],\n",
    "                   qv[0, :] * sv[1, :] - qv[1, :] * sv[0, :]))\n",
    "\n",
    "    # Calculate the final quaternion product\n",
    "    p = np.vstack((q0 * s0 - np.sum(qv * sv, axis=0), q0 * sv + s0 * qv + c))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eul_to_quat(phi, theta, psi, flip=True):\n",
    "    \"\"\"\n",
    "    Converts Euler angles to quaternions.\n",
    "\n",
    "    Parameters:\n",
    "    - phi (np.ndarray): Array of rotations around the z-axis.\n",
    "    - theta (np.ndarray): Array of rotations around the y-axis.\n",
    "    - psi (np.ndarray): Array of rotations around the x-axis.\n",
    "    - flip (bool, optional): If True, flips the sign of the psi component. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: An array of quaternions representing the rotations. Each quaternion is\n",
    "      represented as a column in a 4xN array, where N is the number of sets of Euler angles.\n",
    "\n",
    "    Notes:\n",
    "    - The function constructs individual quaternions for rotations around the z, y, and x axes\n",
    "      (qz, qy, qzs respectively) and then combines them through quaternion multiplication to\n",
    "      obtain the final quaternion representing the combined rotation.\n",
    "    - The `flip` parameter can be used to adjust for different conventions in the definition\n",
    "      of rotations.\n",
    "    \"\"\"\n",
    "    # Initialize a zero array for non-rotational components\n",
    "    zros = np.zeros(phi.shape[0])\n",
    "    \n",
    "    # Construct quaternions for rotations around z, y, and (optionally flipped) x axes\n",
    "    qz = np.vstack((np.cos(phi / 2), zros, zros, -np.sin(phi / 2)))\n",
    "    qy = np.vstack((np.cos(theta / 2), zros, -np.sin(theta / 2), zros))\n",
    "    sp = -np.sin(psi / 2) if flip else np.sin(psi / 2)\n",
    "    qzs = np.vstack((np.cos(psi / 2), zros, zros, sp))\n",
    "    \n",
    "    # Combine the rotations through quaternion multiplication\n",
    "    q = q_product(qzs, q_product(qy, qz))\n",
    "    \n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ac7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star(starfile, skip, keep_index=False):\n",
    "    \"\"\"\n",
    "    Parses a STAR file and returns the data as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - starfile (str): The path to the STAR file to be parsed.\n",
    "    - skip (int): The number of lines to skip at the beginning of the file before starting\n",
    "      to look for headers. This is useful for skipping comments or metadata at the top of the file.\n",
    "    - keep_index (bool, optional): If True, keeps the original index (column number) in the header\n",
    "      names. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A pandas DataFrame containing the data from the STAR file, with columns\n",
    "      named according to the headers found in the file.\n",
    "\n",
    "    Notes:\n",
    "    - The function first scans the file to find headers (lines starting with \"_rln\"). It records\n",
    "      these headers and determines where the data section starts.\n",
    "    - If `keep_index` is False, the function strips the leading \"_rln\" and trailing index number\n",
    "      from the header names, leaving a more readable column name.\n",
    "    - After identifying the headers and the start of the data section, the function reads the\n",
    "      data into a pandas DataFrame, using the headers as column names.\n",
    "    - This function is specifically tailored for STAR files used in cryo-EM data processing and\n",
    "      may not be suitable for STAR files with a significantly different format.\n",
    "    \"\"\"\n",
    "    headers = []  # List to store header names\n",
    "    foundheader = False  # Flag to indicate when headers start\n",
    "    ln = 0  # Line number counter\n",
    "\n",
    "    # Open the STAR file and scan for headers\n",
    "    with open(starfile, 'rU') as f:\n",
    "        for l in f:\n",
    "            if ln < skip:\n",
    "                ln += 1\n",
    "                continue\n",
    "            if l.startswith(\"_rln\"):\n",
    "                foundheader = True\n",
    "                if keep_index:\n",
    "                    head = l.rstrip()\n",
    "                else:\n",
    "                    head = l.split('#')[0].rstrip().lstrip('_')\n",
    "                headers.append(head)\n",
    "            else:\n",
    "                if foundheader:\n",
    "                    break  # Stop scanning once headers are found and data section begins\n",
    "            ln += 1\n",
    "\n",
    "    # Read the data section into a pandas DataFrame\n",
    "    star = pd.read_table(starfile, skiprows=ln, delimiter='\\s+', header=None)\n",
    "    star.columns = headers  # Assign column names based on headers\n",
    "\n",
    "    return star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64af961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_star_optics(starfile, keep_index=False):\n",
    "    \"\"\"\n",
    "    Parses the optics section of a STAR file and returns the data as a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - starfile (str): The path to the STAR file to be parsed.\n",
    "    - keep_index (bool, optional): If True, keeps the original index (column number) in the header\n",
    "      names. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing:\n",
    "        - pd.DataFrame: A pandas DataFrame containing the first row of data from the optics section\n",
    "          of the STAR file, with columns named according to the headers found in the file.\n",
    "        - int: The line number where the data section ends, useful for further parsing.\n",
    "\n",
    "    Notes:\n",
    "    - The function scans the file for headers starting with \"_rln\". These headers define the columns\n",
    "      of the optics section.\n",
    "    - If `keep_index` is False, the function cleans the header names by removing the leading \"_rln\"\n",
    "      and any trailing index number, making the column names more readable.\n",
    "    - The function reads only the first row of data under the headers into a DataFrame, assuming\n",
    "      that the optics section contains a single set of parameters.\n",
    "    - This function is useful for extracting optics-related metadata from STAR files used in\n",
    "      cryo-EM data processing.\n",
    "    \"\"\"\n",
    "    headers = []  # List to store header names\n",
    "    foundheader = False  # Flag to indicate when headers start\n",
    "    ln = 0  # Line number counter\n",
    "\n",
    "    # Open the STAR file and scan for headers\n",
    "    with open(starfile, 'r') as f:  # Adjusted for Python 3 compatibility\n",
    "        for l in f:\n",
    "            if l.startswith(\"_rln\"):\n",
    "                foundheader = True\n",
    "                if keep_index:\n",
    "                    head = l.rstrip()\n",
    "                else:\n",
    "                    head = l.split('#')[0].rstrip().lstrip('_')\n",
    "                headers.append(head)\n",
    "            else:\n",
    "                if foundheader:\n",
    "                    break  # Stop scanning once headers are found and data section begins\n",
    "\n",
    "    # Read the first row of data into a pandas DataFrame\n",
    "    star = pd.read_table(starfile, skiprows=ln, delimiter='\\s+', header=None, nrows=1)\n",
    "    star.columns = headers  # Assign column names based on headers\n",
    "\n",
    "    return (star, ln + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4efbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_align_data(align_star_file, flip):\n",
    "    \"\"\"\n",
    "    Extracts alignment data and microscope parameters from a RELION STAR file.\n",
    "\n",
    "    Parameters:\n",
    "    - align_star_file (str): Path to the STAR file containing alignment and microscope parameters.\n",
    "    - flip (bool): Indicates whether to flip the sign of the psi component when converting\n",
    "      Euler angles to quaternions.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing:\n",
    "        - sh (tuple): A tuple of numpy arrays (shx, shy) representing the shifts in X and Y.\n",
    "        - q (np.ndarray): A numpy array of quaternions representing the rotations.\n",
    "        - U (np.ndarray): A numpy array containing the defocus U values.\n",
    "        - V (np.ndarray): A numpy array containing the defocus V values.\n",
    "\n",
    "    Notes:\n",
    "    - The function first checks if the STAR file is in the old or new RELION format by looking\n",
    "      for the \"data_optics\" section.\n",
    "    - It then parses the optics and particles sections accordingly using `parse_star` and\n",
    "      `parse_star_optics` functions to extract the required data.\n",
    "    - Microscope parameters such as voltage, spherical aberration, and amplitude contrast are\n",
    "      extracted from the optics section.\n",
    "    - Alignment parameters including defocus values, shifts, and Euler angles are extracted from\n",
    "      the particles section.\n",
    "    - Shifts are adjusted based on available columns and pixel size, and Euler angles are\n",
    "      converted to quaternions.\n",
    "    - The function is designed to work with RELION STAR files and may need adjustments for\n",
    "      compatibility with other formats or versions.\n",
    "    \"\"\"\n",
    "    relion_old = True\n",
    "    with open(align_star_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"data_optics\"):\n",
    "                relion_old = False\n",
    "                break\n",
    "\n",
    "    if relion_old:\n",
    "        skip = 0\n",
    "        df = parse_star(align_star_file, skip, keep_index=False)\n",
    "        df0 = df\n",
    "    else:\n",
    "        print('RELION Optics Group found.')\n",
    "        df0, skip = parse_star_optics(align_star_file, keep_index=False)\n",
    "        df = parse_star(align_star_file, skip, keep_index=False)\n",
    "\n",
    "    try:\n",
    "        p.EkV = float(df0['rlnVoltage'].values[0])\n",
    "        p.Cs = float(df0['rlnSphericalAberration'].values[0])\n",
    "        p.AmpContrast = float(df0['rlnAmplitudeContrast'].values[0])\n",
    "    except:\n",
    "        print('missing microscope parameters')\n",
    "        exit(1)\n",
    "\n",
    "    try:\n",
    "        U = df['rlnDefocusU'].values\n",
    "        V = df['rlnDefocusV'].values\n",
    "    except:\n",
    "        print(\"missing defocus\")\n",
    "        exit(1)\n",
    "\n",
    "    # Handling shifts\n",
    "    if 'rlnOriginX' in df.columns and 'rlnOriginY' in df.columns:\n",
    "        shx = df['rlnOriginX'].values\n",
    "        shy = df['rlnOriginY'].values\n",
    "    elif 'rlnOriginXAngst' in df.columns and 'rlnOriginYAngst' in df.columns:\n",
    "        shx = df['rlnOriginXAngst'].values / p.pix_size\n",
    "        shy = df['rlnOriginYAngst'].values / p.pix_size\n",
    "    else:\n",
    "        print(f\"Warning: missing relion origin data in {align_star_file}\")\n",
    "        shx = U * 0.\n",
    "        shy = shx\n",
    "    sh = (shx, shy)\n",
    "\n",
    "    # Handling Euler angles and converting to quaternions\n",
    "    try:\n",
    "        phi = np.deg2rad(df['rlnAngleRot'].values)\n",
    "        theta = np.deg2rad(df['rlnAngleTilt'].values)\n",
    "        psi = np.deg2rad(df['rlnAnglePsi'].values)\n",
    "    except:\n",
    "        print(\"missing Euler angles\")\n",
    "        exit(1)\n",
    "    q = eul_to_quat(phi, theta, psi, flip)\n",
    "\n",
    "    return (sh, q, U, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf19ddb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a logger for error reporting\n",
    "_logger = logging.getLogger(__name__)\n",
    "_logger.setLevel(logging.DEBUG)\n",
    "\n",
    "def augment(q):\n",
    "    \"\"\"\n",
    "    Augments a set of quaternions by adding their conjugates to the set.\n",
    "\n",
    "    Parameters:\n",
    "    - q (np.ndarray): A numpy array of shape (4, N) representing a set of quaternions,\n",
    "      where N is the number of quaternions.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: An augmented numpy array of shape (4, 2N) containing the original\n",
    "      set of quaternions followed by their conjugates.\n",
    "\n",
    "    Raises:\n",
    "    - AssertionError: If the input array does not have the correct shape (i.e., does not\n",
    "      have 4 rows representing quaternions).\n",
    "\n",
    "    Notes:\n",
    "    - The conjugate of a quaternion [q0, q1, q2, q3] is defined as [q0, -q1, -q2, -q3].\n",
    "    - This function is useful for operations that require both a quaternion and its inverse,\n",
    "      such as applying rotations and their reversals.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert (q.shape[0] == 4)  # Ensure the input array represents quaternions\n",
    "    except AssertionError:\n",
    "        _logger.error('subroutine augment: q has wrong dimensions')\n",
    "        _logger.exception('subroutine augment: q has wrong dimensions')\n",
    "        raise  # Reraise the exception to ensure it's caught by calling code\n",
    "\n",
    "    # Calculate the conjugate of each quaternion\n",
    "    qc = np.vstack((-q[1, :], q[0, :], -q[3, :], q[2, :]))\n",
    "\n",
    "    # Augment the original set with the conjugates\n",
    "    q = np.hstack((q, qc))\n",
    "\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d63c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0610be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sense(Enum):\n",
    "    \"\"\"\n",
    "    An enumeration to represent the direction of projection or alignment.\n",
    "    \n",
    "    Attributes:\n",
    "    - FWD (int): Represents the forward direction.\n",
    "    - REV (int): Represents the reverse direction.\n",
    "    \n",
    "    Methods:\n",
    "    - from_index(idx: int) -> 'Sense': Converts an integer index to a Sense enum.\n",
    "    - to_index(self) -> int: Converts the Sense enum to an integer index.\n",
    "    \"\"\"\n",
    "    FWD = 1\n",
    "    REV = -1\n",
    "\n",
    "    @staticmethod\n",
    "    def from_index(idx: int) -> 'Sense':\n",
    "        \"\"\"\n",
    "        Converts an integer index to a Sense enum.\n",
    "        \n",
    "        Parameters:\n",
    "        - idx (int): The index to convert.\n",
    "        \n",
    "        Returns:\n",
    "        - Sense: The corresponding Sense enum value.\n",
    "        \n",
    "        Raises:\n",
    "        - ValueError: If the index is invalid.\n",
    "        \"\"\"\n",
    "        if idx == 0:\n",
    "            return Sense.FWD\n",
    "        if idx == 1:\n",
    "            return Sense.REV\n",
    "        raise ValueError(\"Invalid index\")\n",
    "\n",
    "    def to_index(self) -> int:\n",
    "        \"\"\"\n",
    "        Converts the Sense enum to an integer index.\n",
    "        \n",
    "        Returns:\n",
    "        - int: The corresponding index value.\n",
    "        \"\"\"\n",
    "        return 0 if self == Sense.FWD else 1\n",
    "\n",
    "class Anchor:\n",
    "    \"\"\"\n",
    "    Represents an anchor point with associated properties.\n",
    "    \n",
    "    Parameters:\n",
    "    - CC (int): Cross-correlation coefficient, defaulting to 1.\n",
    "    - sense (Sense): The direction of the projection, defaulting to Sense.FWD.\n",
    "    \n",
    "    Attributes:\n",
    "    - CC (int): Stores the cross-correlation coefficient.\n",
    "    - sense (Sense): Stores the direction of the projection.\n",
    "    \"\"\"\n",
    "    def __init__(self, CC: int = 1, sense: Sense = Sense.FWD):\n",
    "        self.CC: int = CC\n",
    "        self.sense: Sense = sense\n",
    "\n",
    "class _ProjectionDirections:\n",
    "    \"\"\"\n",
    "    Manages and processes projection direction data, including thresholds, bin centers, defocus values, and more.\n",
    "    \n",
    "    Attributes:\n",
    "    - Various attributes to store thresholds, bin centers, defocus values, microscope origins, full position data,\n",
    "      quaternion data, image indices, threshold IDs, occupancy data, anchor points, and neighbor graph data.\n",
    "    \n",
    "    Methods:\n",
    "    - load(pd_file=None): Loads projection direction data from a file.\n",
    "    - save(): Saves the current projection direction data to a file.\n",
    "    - update(): Updates the projection direction data based on external parameters or files.\n",
    "    - insert_anchor(id: int, anchor: Anchor): Inserts an anchor point into the dataset.\n",
    "    - remove_anchor(id: int): Removes an anchor point from the dataset.\n",
    "    - deduplicate(arr): Removes duplicate entries from an array.\n",
    "    \n",
    "    Properties:\n",
    "    - Provides access to various subsets or transformations of the data, such as occupancy without duplication,\n",
    "      bin centers without duplication, anchor IDs, thresholded image indices, occupancy for thresholded IDs,\n",
    "      the number of bins, and the number of thresholded entries.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # Initialize attributes with default values or empty structures\n",
    "        self.thres_low: int = p.PDsizeThL\n",
    "        self.thres_high: int = p.PDsizeThH\n",
    "        self.bin_centers: NDArray[Shape[\"3,*\", Any], Float64] = np.empty(shape=(3, 0))\n",
    "        self.defocus: NDArray[Shape[\"*\"], Float64] = np.empty(0)\n",
    "        self.microscope_origin: Tuple[NDArray[Shape[\"*\"], Float64], NDArray[Shape[\"*\"], Float64]] = (np.empty(0), np.empty(0))\n",
    "        self.pos_full: NDArray[Shape[\"3\", Any], Float64] = np.empty(shape=(3,0))\n",
    "        self.quats_full: NDArray[Shape[\"4\", Any], Float64] = np.empty(shape=(4,0))\n",
    "        self.image_indices_full: NDArray[Shape[\"*\"], List[Int]] = np.empty(0, dtype=object)\n",
    "        self.thres_ids: NDArray[Shape[\"*\"], Int64] = np.empty(0, dtype=np.int64)\n",
    "        self.occupancy_full: NDArray[Shape[\"*\"], Int] = np.empty(0, dtype=int)\n",
    "        self.anchors: Dict[int, Anchor] = {}\n",
    "        self.trash_ids: Set[int] = set()\n",
    "        self.reembed_ids: Set[int] = set()\n",
    "        self.neighbor_graph: Dict[str, Any] = {}\n",
    "        self.neighbor_subgraph: List[Dict[str, Any]] = []\n",
    "        self.neighbor_graph_pruned: Dict[str, Any] = {}\n",
    "        self.neighbor_subgraph_pruned: List[Dict[str, Any]] = []\n",
    "        self.pos_thresholded: NDArray[Shape[\"3\", Any], Float64] = np.empty(shape=(3,0))\n",
    "        self.theta_thresholded: NDArray[Shape[\"*\"], Float64] = np.empty(0)\n",
    "        self.phi_thresholded: NDArray[Shape[\"*\"], Float64] = np.empty(0)\n",
    "        self.cluster_ids: NDArray[Shape[\"*\"], Int] = np.empty(0, dtype=int)\n",
    "\n",
    "    def load(self, pd_file=None):\n",
    "        \"\"\"\n",
    "        Loads projection direction data from a specified file.\n",
    "        \n",
    "        Parameters:\n",
    "        - pd_file (str, optional): The path to the file from which to load data. If None, uses a default path.\n",
    "        \"\"\"\n",
    "        if pd_file is None:\n",
    "            pd_file = p.pd_file\n",
    "        with open(pd_file, 'rb') as f:\n",
    "            self.__dict__.update(pickle.load(f))\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\"\n",
    "        Saves the current projection direction data to a file.\n",
    "        \"\"\"\n",
    "        with open(p.pd_file, 'wb') as f:\n",
    "            pickle.dump(self.__dict__, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    def update(self):\n",
    "        \"\"\"\n",
    "        Updates the projection direction data based on external parameters or files.\n",
    "        \"\"\"\n",
    "        # Load if cache exists and store uninitialized\n",
    "        if self.pos_full.size == 0 and os.path.isfile(p.pd_file):\n",
    "            self.load(p.pd_file)\n",
    "\n",
    "        # If uninitialized or things have changed, actually update\n",
    "        force_rebuild = bool(os.environ.get('MANIFOLD_REBUILD_DS', 0))\n",
    "        if force_rebuild or self.pos_full.size == 0 or self.thres_low != p.PDsizeThL or self.thres_high != p.PDsizeThH:\n",
    "            if force_rebuild:\n",
    "                print(\"Rebuilding data store\")\n",
    "                os.environ.pop('MANIFOLD_REBUILD_DS')\n",
    "\n",
    "            print(\"Calculating projection direction information\")\n",
    "            sh, q, U, V = get_align_data(p.align_param_file, flip=True)\n",
    "            df = (U + V) / 2\n",
    "\n",
    "            # Double the number of data points by augmentation\n",
    "            q = augment(q)\n",
    "            df = np.concatenate((df, df))\n",
    "            image_indices, pos_full, bin_centers, occupancy, conjugate_bin_ids = \\\n",
    "                bin_and_threshold(q, p.ang_width, p.PDsizeThL, p.PDsizeThH)\n",
    "            self.thres_low = p.PDsizeThL\n",
    "            self.thres_high = p.PDsizeThH\n",
    "            self.bin_centers = bin_centers\n",
    "            self.defocus = df\n",
    "            self.microscope_origin = sh\n",
    "            self.pos_full = pos_full\n",
    "            self.quats_full = q\n",
    "            self.image_indices_full = image_indices\n",
    "            self.thres_ids = conjugate_bin_ids\n",
    "            self.occupancy_full = occupancy\n",
    "            self.anchors = {}\n",
    "            self.trash_ids = set()\n",
    "            self.pos_thresholded = self.bin_centers[:, self.thres_ids]\n",
    "            self.phi_thresholded = np.arctan2(self.pos_thresholded[1, :], self.pos_thresholded[0, :]) * 180. / np.pi\n",
    "            self.theta_thresholded = np.arccos(self.pos_thresholded[2, :]) * 180. / np.pi\n",
    "            self.neighbor_graph, self.neighbor_subgraph = FindCCGraph(self.thresholded_image_indices, self.n_bins, self.pos_thresholded)\n",
    "\n",
    "            def get_cluster_ids(G):\n",
    "                \"\"\"\n",
    "                Generates cluster IDs based on the connected components in the neighbor graph.\n",
    "                \n",
    "                Parameters:\n",
    "                - G (Dict[str, Any]): The neighbor graph.\n",
    "                \n",
    "                Returns:\n",
    "                - NDArray[Shape[\"*\"], Int]: An array of cluster IDs.\n",
    "                \"\"\"\n",
    "                nodesColor = np.zeros(G['nNodes'], dtype='int')\n",
    "                for i, nodesCC in enumerate(G['NodesConnComp']):\n",
    "                    nodesColor[nodesCC] = i\n",
    "                return nodesColor\n",
    "            self.cluster_ids = get_cluster_ids(self.neighbor_graph)\n",
    "            p.numberofJobs = len(self.thres_ids)\n",
    "            p.save()\n",
    "            self.save()\n",
    "\n",
    "    def insert_anchor(self, id: int, anchor: Anchor):\n",
    "        \"\"\"\n",
    "        Inserts an anchor point into the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        - id (int): The identifier for the anchor point.\n",
    "        - anchor (Anchor): The anchor point to insert.\n",
    "        \"\"\"\n",
    "        self.anchors[id] = anchor\n",
    "\n",
    "    def remove_anchor(self, id: int):\n",
    "        \"\"\"\n",
    "        Removes an anchor point from the dataset.\n",
    "        \n",
    "        Parameters:\n",
    "        - id (int): The identifier for the anchor point to remove.\n",
    "        \"\"\"\n",
    "        if id in self.anchors:\n",
    "            self.anchors.pop(id)\n",
    "\n",
    "    def deduplicate(self, arr):\n",
    "        \"\"\"\n",
    "        Removes duplicate entries from an array by keeping only the first half of the data if the array size is even,\n",
    "        or the second half if the array size is odd.\n",
    "        \n",
    "        Parameters:\n",
    "        - arr (NDArray): The array from which to remove duplicates.\n",
    "        \n",
    "        Returns:\n",
    "        - NDArray: The deduplicated array.\n",
    "        \"\"\"\n",
    "        mid = arr.shape[-1] // 2\n",
    "        if 2 * mid == arr.shape[-1]:\n",
    "            return arr[:mid]\n",
    "        else:\n",
    "            return arr[mid:]\n",
    "\n",
    "    @property\n",
    "    def occupancy_no_duplication(self):\n",
    "        \"\"\"\n",
    "        Returns the occupancy data without duplication.\n",
    "        \n",
    "        Returns:\n",
    "        - NDArray: The deduplicated occupancy data.\n",
    "        \"\"\"\n",
    "        return self.deduplicate(self.occupancy_full)\n",
    "\n",
    "    @property\n",
    "    def bin_centers_no_duplication(self):\n",
    "        \"\"\"\n",
    "        Returns the bin center data without duplication.\n",
    "        \n",
    "        Returns:\n",
    "        - NDArray: The deduplicated bin center data.\n",
    "        \"\"\"\n",
    "        mid = self.bin_centers.shape[1] // 2\n",
    "        if 2 * mid == self.bin_centers.shape[1]:\n",
    "            return self.bin_centers[:, :mid]\n",
    "        else:\n",
    "            return self.bin_centers[:, mid:]\n",
    "\n",
    "    @property\n",
    "    def anchor_ids(self):\n",
    "        \"\"\"\n",
    "        Returns a sorted list of anchor IDs.\n",
    "        \n",
    "        Returns:\n",
    "        - List[int]: The sorted list of anchor IDs.\n",
    "        \"\"\"\n",
    "        return sorted(list(self.anchors.keys()))\n",
    "\n",
    "    @property\n",
    "    def thresholded_image_indices(self):\n",
    "        \"\"\"\n",
    "        Returns the image indices for thresholded data, applying the high threshold limit.\n",
    "        \n",
    "        Returns:\n",
    "        - NDArray: The thresholded image indices.\n",
    "        \"\"\"\n",
    "        thres_images = self.image_indices_full[self.thres_ids]\n",
    "        for i in range(thres_images.size):\n",
    "            if len(thres_images[i]) > self.thres_high:\n",
    "                thres_images[i] = thres_images[i][:self.thres_high]\n",
    "        return thres_images\n",
    "\n",
    "    @property\n",
    "    def occupancy(self):\n",
    "        \"\"\"\n",
    "        Returns the occupancy data for thresholded IDs.\n",
    "        \n",
    "        Returns:\n",
    "        - NDArray: The occupancy data for thresholded IDs.\n",
    "        \"\"\"\n",
    "        return self.occupancy_full[self.thres_ids]\n",
    "\n",
    "    @property\n",
    "    def n_bins(self):\n",
    "        \"\"\"\n",
    "        Returns the number of bins.\n",
    "        \n",
    "        Returns:\n",
    "        - int: The number of bins.\n",
    "        \"\"\"\n",
    "        return self.bin_centers.shape[1]\n",
    "\n",
    "    @property\n",
    "    def n_thresholded(self):\n",
    "        \"\"\"\n",
    "        Returns the number of thresholded entries.\n",
    "        \n",
    "        Returns:\n",
    "        - int: The number of thresholded entries.\n",
    "        \"\"\"\n",
    "        return len(self.thres_ids)\n",
    "\n",
    "class _DataStore:\n",
    "    \"\"\"\n",
    "    Implements the Singleton design pattern to ensure a single instance of the data store.\n",
    "    This class acts as a manager for _ProjectionDirections, providing global access to projection\n",
    "    direction data and functionalities.\n",
    "    \n",
    "    Methods:\n",
    "    - get_prds(): Updates and returns the _ProjectionDirections instance, ensuring the data is current.\n",
    "    \"\"\"\n",
    "    _projection_directions = _ProjectionDirections()\n",
    "\n",
    "    def __new__(cls):\n",
    "        \"\"\"\n",
    "        Ensures that only one instance of _DataStore exists.\n",
    "        \n",
    "        Returns:\n",
    "        - _DataStore: The singleton instance of the _DataStore class.\n",
    "        \"\"\"\n",
    "        if not hasattr(cls, 'instance'):\n",
    "            cls.instance = super(_DataStore, cls).__new__(cls)\n",
    "        return cls.instance\n",
    "\n",
    "    def get_prds(self):\n",
    "        \"\"\"\n",
    "        Retrieves the current _ProjectionDirections instance after updating it.\n",
    "        \n",
    "        Returns:\n",
    "        - _ProjectionDirections: The updated _ProjectionDirections instance.\n",
    "        \"\"\"\n",
    "        self._projection_directions.update()\n",
    "        return self._projection_directions\n",
    "\n",
    "data_store = _DataStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995c2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fout1(filename, **kwargs):\n",
    "    \"\"\"\n",
    "    Saves the given keyword arguments to a file using Python's pickle serialization.\n",
    "\n",
    "    Parameters:\n",
    "    - filename (str): The name of the file where the data will be saved.\n",
    "    - **kwargs: Arbitrary keyword arguments to be saved.\n",
    "\n",
    "    This function uses the highest protocol available for pickling to ensure efficiency\n",
    "    and potentially the most compact file size.\n",
    "    \"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(kwargs, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    # The file is automatically closed after the with block, so f.close() is unnecessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08fec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annularMask(a: float, b: float, N: int, M: int):\n",
    "    \"\"\"\n",
    "    Generates an N x M matrix representing an annular (donut-shaped) mask.\n",
    "\n",
    "    Parameters:\n",
    "    - a (float): The inner radius of the annulus.\n",
    "    - b (float): The outer radius of the annulus.\n",
    "    - N (int): The number of rows in the output matrix.\n",
    "    - M (int): The number of columns in the output matrix.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A 2D NumPy array of shape (N, M) where pixels within the annular region\n",
    "      are marked with 1, and all other pixels are marked with 0.\n",
    "\n",
    "    The annulus is centered on the pixel (N/2, M/2). This function iterates over each pixel\n",
    "    to determine its inclusion within the specified annular region.\n",
    "    \"\"\"\n",
    "    aSq = a * a\n",
    "    bSq = b * b\n",
    "    mask = np.zeros((N, M))\n",
    "    for xx in range(N):\n",
    "        xDist = xx - N / 2 + 1\n",
    "        xDistSq = xDist * xDist\n",
    "        for yy in range(M):\n",
    "            yDist = yy - M / 2\n",
    "            yDistSq = yDist * yDist\n",
    "            rSq = xDistSq + yDistSq\n",
    "            mask[xx, yy] = (rSq >= aSq) & (rSq < bSq)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dd1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def _q_product_single(q1, q2):\n",
    "    \"\"\"\n",
    "    Computes the product of two quaternions using Numba for JIT compilation.\n",
    "\n",
    "    Parameters:\n",
    "    - q1 (np.ndarray): The first quaternion as a NumPy array.\n",
    "    - q2 (np.ndarray): The second quaternion as a NumPy array.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The product of the two quaternions as a new NumPy array.\n",
    "\n",
    "    This function is optimized for performance with Numba's nopython mode, ensuring\n",
    "    that the computation is compiled to machine code for faster execution.\n",
    "    \"\"\"\n",
    "    return np.array([\n",
    "        q1[0] * q2[0] - q1[1] * q2[1] - q1[2] * q2[2] - q1[3] * q2[3],\n",
    "        q1[0] * q2[1] + q1[1] * q2[0] + q1[2] * q2[3] - q1[3] * q2[2],\n",
    "        q1[0] * q2[2] - q1[1] * q2[3] + q1[2] * q2[0] + q1[3] * q2[1],\n",
    "        q1[0] * q2[3] + q1[1] * q2[2] - q1[2] * q2[1] + q1[3] * q2[0],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2205e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def _optfunc(a, q):\n",
    "    \"\"\"\n",
    "    Optimized function to compute a quaternion operation, intended for use in optimization problems.\n",
    "\n",
    "    Parameters:\n",
    "    - a (np.ndarray): A NumPy array representing angles.\n",
    "    - q (np.ndarray): A target quaternion for the operation.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The result of the quaternion operation as a NumPy array.\n",
    "\n",
    "    This function constructs three quaternions based on the input angles 'a', performs\n",
    "    quaternion multiplication, and compares the result to the target quaternion 'q'.\n",
    "    It is optimized with Numba's nopython mode for faster execution.\n",
    "    \"\"\"\n",
    "    b = 0.5 * a\n",
    "    q1 = np.array([np.cos(b[0]), 0., 0., -np.sin(b[0])])\n",
    "    q2 = np.array([np.cos(b[1]), 0., -np.sin(b[1]), 0.])\n",
    "    q3 = np.array([np.cos(b[2]), 0., 0., -np.sin(b[2])])\n",
    "    return q - _q_product_single(q3, _q_product_single(q2, q1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c1d1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2Spider(q: np.ndarray) -> tuple:\n",
    "    \"\"\"\n",
    "    Converts a quaternion to a rotation sequence in the Spider 3D convention.\n",
    "\n",
    "    Parameters:\n",
    "    - q (np.ndarray): A quaternion represented as a 1D NumPy array of shape [4].\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple (phi, theta, psi) representing the rotation sequence in radians.\n",
    "\n",
    "    The function normalizes the input quaternion to ensure it represents a valid rotation.\n",
    "    It then uses an optimization process to find the Euler angles (phi, theta, psi) that correspond\n",
    "    to the given quaternion. The Spider 3D convention is used, which is common in cryo-EM for\n",
    "    representing 3D orientations.\n",
    "\n",
    "    The optimization process minimizes the deviation between the input quaternion and the quaternion\n",
    "    that would result from the calculated Euler angles, ensuring an accurate conversion.\n",
    "\n",
    "    Note:\n",
    "    - This function assumes the input quaternion is a unit quaternion.\n",
    "    - The optimization process uses the Levenberg-Marquardt algorithm through scipy's least_squares method.\n",
    "    \"\"\"\n",
    "    # Normalize the quaternion to ensure it's a unit quaternion\n",
    "    q = q / np.linalg.norm(q)\n",
    "\n",
    "    # Define the deviation function for optimization\n",
    "    def dev1(a):\n",
    "        return _optfunc(a, q)  # Assuming _optfunc is defined elsewhere to calculate deviation\n",
    "\n",
    "    # Set optimization bounds and tolerance\n",
    "    lb = -np.inf\n",
    "    ub = np.inf\n",
    "    tol = 1e-12\n",
    "\n",
    "    # Initial guess for the Euler angles\n",
    "    a0 = np.array([0, 0, 0])\n",
    "\n",
    "    # Perform optimization to find the best-fit Euler angles\n",
    "    res = optimize.least_squares(dev1, a0, bounds=(lb, ub), ftol=tol, method='lm')\n",
    "    a = res.x\n",
    "\n",
    "    # Extract the Euler angles from the optimization result\n",
    "    phi, theta, psi = a\n",
    "\n",
    "    return (phi, theta, psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4f8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProjectMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d37c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quaternion_matrix(quaternion):\n",
    "    \"\"\"\n",
    "    Return homogeneous rotation matrix from quaternion.\n",
    "\n",
    "    Parameters:\n",
    "    - quaternion (list or np.ndarray): Quaternion represented as [w, x, y, z].\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A 4x4 homogeneous rotation matrix.\n",
    "\n",
    "    Examples:\n",
    "    >>> M = quaternion_matrix([0.99810947, 0.06146124, 0, 0])\n",
    "    >>> numpy.allclose(M, rotation_matrix(0.123, [1, 0, 0]))\n",
    "    True\n",
    "    >>> M = quaternion_matrix([1, 0, 0, 0])\n",
    "    >>> numpy.allclose(M, numpy.identity(4))\n",
    "    True\n",
    "    >>> M = quaternion_matrix([0, 1, 0, 0])\n",
    "    >>> numpy.allclose(M, numpy.diag([1, -1, -1, 1]))\n",
    "    True\n",
    "    \"\"\"\n",
    "    q = np.array(quaternion, dtype=np.float64, copy=True)\n",
    "    n = np.dot(q, q)\n",
    "    if n < np.finfo(float).eps * 4.0:\n",
    "        return np.identity(4)\n",
    "    q *= math.sqrt(2.0 / n)\n",
    "    q = np.outer(q, q)\n",
    "    return np.array([\n",
    "        [1.0 - q[2, 2] - q[3, 3], q[1, 2] - q[3, 0], q[1, 3] + q[2, 0], 0.0],\n",
    "        [q[1, 2] + q[3, 0], 1.0 - q[1, 1] - q[3, 3], q[2, 3] - q[1, 0], 0.0],\n",
    "        [q[1, 3] - q[2, 0], q[2, 3] + q[1, 0], 1.0 - q[1, 1] - q[2, 2], 0.0],\n",
    "        [0.0, 0.0, 0.0, 1.0]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eulerRotMatrix3DSpider(Phi, Theta, Psi, deg):\n",
    "    \"\"\"\n",
    "    Computes a rotation matrix from Euler angles using the SPIDER convention.\n",
    "\n",
    "    Parameters:\n",
    "    - Phi, Theta, Psi (float): Euler angles.\n",
    "    - deg (bool): If True, angles are given in degrees; otherwise, in radians.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A 3x3 rotation matrix.\n",
    "\n",
    "    This function calculates the rotation matrix for a given set of Euler angles\n",
    "    following the SPIDER convention. If 'deg' is True, the angles are first converted\n",
    "    to radians.\n",
    "    \"\"\"\n",
    "    if deg:\n",
    "        Phi = math.radians(Phi)\n",
    "        Theta = math.radians(Theta)\n",
    "        Psi = math.radians(Psi)\n",
    "    R = np.array([\n",
    "        [np.cos(Phi) * np.cos(Psi) * np.cos(Theta) - np.sin(Phi) * np.sin(Psi),\n",
    "         np.cos(Psi) * np.cos(Theta) * np.sin(Phi) + np.cos(Phi) * np.sin(Psi),\n",
    "         -np.cos(Psi) * np.sin(Theta)],\n",
    "        [-np.cos(Psi) * np.sin(Phi) - np.cos(Phi) * np.cos(Theta) * np.sin(Psi),\n",
    "         np.cos(Phi) * np.cos(Psi) - np.cos(Theta) * np.sin(Phi) * np.sin(Psi),\n",
    "         np.sin(Psi) * np.sin(Theta)],\n",
    "        [np.cos(Phi) * np.sin(Theta),\n",
    "         np.sin(Phi) * np.sin(Theta),\n",
    "         np.cos(Theta)]\n",
    "    ])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940d538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateVolumeEuler(vol, sym, deg):\n",
    "    \"\"\"\n",
    "    Rotates a 3D volume using Euler angles.\n",
    "\n",
    "    Parameters:\n",
    "    - vol (np.ndarray): The input 3D volume to be rotated.\n",
    "    - sym (list or np.ndarray): Euler angles [Phi, Theta, Psi] for the rotation.\n",
    "    - deg (bool): Specifies if the Euler angles are in degrees.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: The rotated 3D volume.\n",
    "\n",
    "    The function computes the rotation matrix from the Euler angles and applies it to the input volume.\n",
    "    The 'nearest' mode is used for interpolation during the affine transformation.\n",
    "    \"\"\"\n",
    "    dims = vol.shape\n",
    "    rotmat = eulerRotMatrix3DSpider(sym[2], sym[1], sym[0], deg)\n",
    "\n",
    "    # Inverse transformation\n",
    "    T_inv = rotmat\n",
    "\n",
    "    c_in = 0.5 * np.array(dims)\n",
    "    c_out = 0.5 * np.array(dims)\n",
    "    cen_offset = c_in - np.dot(T_inv, c_out)\n",
    "    rho = affine_transform(input=vol, matrix=T_inv, offset=cen_offset, output_shape=dims, mode='nearest')\n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539fb4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEuler_from_PD(PD, deg):\n",
    "    \"\"\"\n",
    "    Converts projection direction (PD) to Euler angles.\n",
    "\n",
    "    Parameters:\n",
    "    - PD (np.ndarray): The projection direction.\n",
    "    - deg (int): Specifies the output format of the Euler angles. If 1, angles are in degrees;\n",
    "      if 2, angles are in degrees and normalized to [0, 360).\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the Euler angles [Phi, Theta, Psi] and the quaternion representation.\n",
    "\n",
    "    This function calculates Euler angles from a given projection direction and also provides\n",
    "    the quaternion representation of the orientation.\n",
    "    \"\"\"\n",
    "    Qr = np.array([1 + PD[2], PD[1], -PD[0], 0]).T\n",
    "    q1 = Qr / np.linalg.norm(Qr)\n",
    "    phi, theta, psi = q2Spider(q1) \n",
    "    if deg == 1:\n",
    "        phi = np.degrees(phi)\n",
    "        theta = np.degrees(theta)\n",
    "        psi = np.degrees(psi)\n",
    "    elif deg == 2:\n",
    "        phi = np.degrees(phi) % 360\n",
    "        theta = np.degrees(theta) % 360\n",
    "        psi = np.degrees(psi) % 360\n",
    "    sym = np.array([phi, theta, psi])\n",
    "    return sym, q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b187147",
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectMask(vol, PD):\n",
    "    \"\"\"\n",
    "    Projects a 3D volume onto a 2D plane using a given projection direction (PD) and generates a mask.\n",
    "\n",
    "    Parameters:\n",
    "    - vol (np.ndarray): The input 3D volume.\n",
    "    - PD (np.ndarray): The projection direction.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: A 2D mask generated from the projected volume.\n",
    "\n",
    "    The function rotates the volume according to the projection direction, sums up the intensity\n",
    "    along the z-axis to create a 2D projection, and then thresholds the projection to create a binary mask.\n",
    "    \n",
    "    Note:\n",
    "    - This function relies on `np.swapaxes` to rearrange the axes of the volume for proper orientation.\n",
    "    - `getEuler_from_PD` is an external function that converts the projection direction into Euler angles. \n",
    "      This function is assumed to be defined elsewhere and is crucial for determining the rotation needed.\n",
    "    - `rotateVolumeEuler` applies the rotation to the volume. This function computes the rotation matrix \n",
    "      from Euler angles and uses `affine_transform` from `scipy.ndimage` for the rotation.\n",
    "    - The rotation is based on the inverse transformation principle, where the volume is rotated in the opposite\n",
    "      direction of the given Euler angles to simulate the projection from that direction.\n",
    "    - After rotation, the volume is summed along the z-axis to create a 2D projection. The resulting projection\n",
    "      is then thresholded to generate a binary mask, where pixels with values greater than 1 are set to True.\n",
    "    \"\"\"\n",
    "    vol = np.swapaxes(vol, 0, 2)\n",
    "    nPix = vol.shape[0]\n",
    "    deg = 0\n",
    "    sym, q = getEuler_from_PD(PD, deg)  # External function to convert PD to Euler angles\n",
    "    sym[2] = 0  # As psi=0, input images have already been in-plane rotated\n",
    "    sym = sym * (-1.)  # For inverse transformation\n",
    "    rho = rotateVolumeEuler(vol, sym, deg)  # External function to rotate the volume\n",
    "    msk = np.sum(rho, axis=2)  # Summing the rotated volume along the z-axis\n",
    "    msk = msk.reshape(nPix, nPix).T\n",
    "    msk = msk > 1  # Thresholding to create a binary mask\n",
    "    return msk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491f0524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# projectMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406362db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a basic logger for error handling\n",
    "_logger = logging.getLogger(__name__)\n",
    "_logger.setLevel(logging.DEBUG)\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "@dataclass\n",
    "class FilterParams:\n",
    "    \"\"\"\n",
    "    Class to assist in the creation of image filters.\n",
    "\n",
    "    Attributes:\n",
    "    - method (str): The type of filter, either 'Butter' for Butterworth or 'Gauss' for Gaussian.\n",
    "    - cutoff_freq (float): The Nyquist cutoff frequency, determining the filter's cutoff threshold.\n",
    "    - order (int): The filter order, applicable only for the 'Butter' method.\n",
    "\n",
    "    Methods:\n",
    "    - create_filter(Q): Generates a filter based on the specified parameters and a frequency array Q.\n",
    "    \"\"\"\n",
    "    method: str\n",
    "    cutoff_freq: float\n",
    "    order: int = 0  # Default order set to 0 for flexibility with Gaussian filters\n",
    "\n",
    "    def create_filter(self, Q: NDArray[Any, np.float64]) -> NDArray[Any, np.float64]:\n",
    "        \"\"\"\n",
    "        Creates a filter based on the instance's method, cutoff frequency, and order.\n",
    "\n",
    "        Parameters:\n",
    "        - Q (NDArray): A 2D array of spatial frequencies for which the filter is calculated.\n",
    "\n",
    "        Returns:\n",
    "        - NDArray: A 2D array representing the filter in the frequency domain.\n",
    "\n",
    "        Raises:\n",
    "        - ValueError: If an unsupported filter method is specified.\n",
    "        \"\"\"\n",
    "        if self.method == 'Gauss':\n",
    "            # Gaussian filter formula\n",
    "            G = np.exp(-(np.log(2) / 2.) * (Q / self.cutoff_freq)**2)\n",
    "        elif self.method == 'Butter':\n",
    "            # Butterworth filter formula\n",
    "            G = 1. / np.sqrt(1. + (Q / self.cutoff_freq)**(2 * self.order))\n",
    "        else:\n",
    "            # Handling unsupported filter methods\n",
    "            _logger.error(f'{self.method} filter is unsupported')\n",
    "            raise ValueError(f'{self.method} filter is unsupported')\n",
    "        return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f79c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_fill(img: NDArray[Any, np.float64], angle: float) -> NDArray[Any, np.float64]:\n",
    "    \"\"\"\n",
    "    Rotates an image by a given angle and fills the output image by repeating the input image.\n",
    "\n",
    "    Parameters:\n",
    "    - img (NDArray): The input image as a 2D NumPy array.\n",
    "    - angle (float): The rotation angle in degrees.\n",
    "\n",
    "    Returns:\n",
    "    - NDArray: The rotated image as a 2D NumPy array.\n",
    "\n",
    "    The function first tiles the input image in a 3x3 grid to ensure that no empty spaces appear in the output\n",
    "    image after rotation. It then rotates the tiled image and extracts the central part, which corresponds to\n",
    "    the rotated version of the original input image.\n",
    "    \"\"\"\n",
    "    n_pix = img.shape[0]\n",
    "    in_rep = Image.fromarray(np.tile(img, (3, 3)).astype('float32'), mode='F')\n",
    "    out_rep = np.array(in_rep.rotate(angle, expand=False), dtype=img.dtype)\n",
    "    return out_rep[n_pix:2 * n_pix, n_pix:2 * n_pix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ded61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid(N: int) -> NDArray[Any, np.float64]:\n",
    "    \"\"\"\n",
    "    Creates an NxN grid centered around (0, 0).\n",
    "\n",
    "    Parameters:\n",
    "    - N (int): The size of the grid.\n",
    "\n",
    "    Returns:\n",
    "    - NDArray: A 2D NumPy array representing the grid.\n",
    "\n",
    "    The function generates an NxN grid where each point's value is proportional to its distance from the center,\n",
    "    normalized by the grid size. This can be used for generating spatial frequency grids or other applications\n",
    "    where a centered grid is required.\n",
    "    \"\"\"\n",
    "    a = np.arange(N) - N // 2\n",
    "    X, Y = np.meshgrid(a, a)\n",
    "    return 2 * np.sqrt(X**2 + Y**2) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec533f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quats_to_unit_vecs(q: NDArray[Any, np.float64]) -> NDArray[Any, np.float64]:\n",
    "    \"\"\"\n",
    "    Converts an array of quaternions to corresponding unit vectors representing average projection directions.\n",
    "\n",
    "    Parameters:\n",
    "    - q (NDArray): A 2D NumPy array of quaternions, where each column represents a quaternion.\n",
    "\n",
    "    Returns:\n",
    "    - NDArray: A 2D NumPy array of unit vectors derived from the input quaternions.\n",
    "\n",
    "    The function computes the unit vectors corresponding to the average projection directions based on the input\n",
    "    quaternions. This is useful for converting quaternion representations of orientations into vector representations.\n",
    "    \"\"\"\n",
    "    PDs = 2 * np.vstack((q[1, :] * q[3, :] - q[0, :] * q[2, :], q[0, :] * q[1, :] + q[2, :] * q[3, :],\n",
    "                         q[0, :]**2 + q[3, :]**2 - np.ones((1, q.shape[1])) / 2.0))\n",
    "    return PDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17267ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_psi(q: NDArray[Any, np.float64], ref_vec: NDArray[Any, np.float64]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the psi angle from a quaternion and a reference vector.\n",
    "\n",
    "    Parameters:\n",
    "    - q (NDArray): A quaternion represented as a 1D NumPy array of shape [4].\n",
    "    - ref_vec (NDArray): A reference vector represented as a 1D NumPy array of shape [3].\n",
    "\n",
    "    Returns:\n",
    "    - float: The psi angle in radians, in the interval [-pi, pi].\n",
    "\n",
    "    This function computes the psi angle, which is part of the Euler angles, from a given quaternion and a reference\n",
    "    vector. The calculation is based on the relationship between the quaternion components and the reference vector.\n",
    "    \"\"\"\n",
    "    s = -(1 + ref_vec[2]) * q[3] - ref_vec[0] * q[1] - ref_vec[1] * q[2]\n",
    "    c = (1 + ref_vec[2]) * q[0] + ref_vec[1] * q[1] - ref_vec[0] * q[2]\n",
    "    if c == 0.0:\n",
    "        psi = np.sign(s) * np.pi\n",
    "    else:\n",
    "        psi = 2 * np.arctan(s / c)\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb0b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psi_ang(ref_vec: NDArray[Any, np.float64]) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the psi angle from a reference vector.\n",
    "\n",
    "    Parameters:\n",
    "    - ref_vec (NDArray): A reference vector represented as a 1D NumPy array of shape [3].\n",
    "\n",
    "    Returns:\n",
    "    - float: The psi angle in degrees.\n",
    "\n",
    "    This function computes the psi angle by first converting the reference vector into a quaternion and then\n",
    "    normalizing it. The psi angle is extracted using a function `q2Spider` (assumed to be defined elsewhere),\n",
    "    which converts quaternions to Euler angles. The result is then converted to degrees and normalized to the\n",
    "    interval [0, 360).\n",
    "    \"\"\"\n",
    "    Qr = np.array([1 + ref_vec[2], ref_vec[1], -ref_vec[0], 0])\n",
    "    L2 = np.sum(Qr**2)\n",
    "    if L2 == 0.0:\n",
    "        return 0.0\n",
    "    Qr = Qr / np.sqrt(L2)\n",
    "    _, _, psi = q2Spider(Qr)  # Assuming q2Spider is a predefined function\n",
    "    psi = np.mod(psi, 2 * np.pi) * (180 / np.pi)\n",
    "    return psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286b468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wiener1(CTF1: NDArray[Any, np.float64]) -> NDArray[Any, np.float64]:\n",
    "    \"\"\"\n",
    "    Computes the Wiener filter domain from a given Contrast Transfer Function (CTF).\n",
    "\n",
    "    Parameters:\n",
    "    - CTF1 (NDArray): The Contrast Transfer Function represented as a 2D or 3D NumPy array.\n",
    "\n",
    "    Returns:\n",
    "    - NDArray: The Wiener filter domain as a NumPy array of the same shape as CTF1.\n",
    "\n",
    "    This function calculates the Wiener filter domain by summing the squares of the CTF values across\n",
    "    the first dimension and then adding a constant based on the Signal-to-Noise Ratio (SNR). The SNR is\n",
    "    assumed to be a predefined constant within this function.\n",
    "    \"\"\"\n",
    "    SNR = 5  # Signal-to-Noise Ratio\n",
    "    wiener_dom = 0.\n",
    "    for i in range(CTF1.shape[0]):\n",
    "        wiener_dom += CTF1[i, :, :]**2\n",
    "    wiener_dom += 1. / SNR\n",
    "    return wiener_dom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13b169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctemh_cryoFrank(k: NDArray[Any, np.float64], spherical_aberration: float, defocus: float,\n",
    "                    electron_energy: float, gauss_env_halfwidth: float,\n",
    "                    amplitude_contrast_ratio: float) -> NDArray[Any, np.float64]:\n",
    "    \"\"\"\n",
    "    Calculates the contrast transfer function (CTF) for cryo-EM imaging.\n",
    "\n",
    "    Parameters:\n",
    "    - k (NDArray): A 2D array of spatial frequencies.\n",
    "    - spherical_aberration (float): Spherical aberration (Cs) in mm.\n",
    "    - defocus (float): Defocus in Angstroms. A positive value indicates underfocus.\n",
    "    - electron_energy (float): Electron energy in keV.\n",
    "    - gauss_env_halfwidth (float): Half-width of the Gaussian envelope in A^-2.\n",
    "    - amplitude_contrast_ratio (float): Amplitude contrast ratio obtained from the alignment file.\n",
    "\n",
    "    Returns:\n",
    "    - NDArray: A 2D array representing the CTF.\n",
    "\n",
    "    The function computes the CTF considering the effects of spherical aberration, defocus, electron wavelength,\n",
    "    and a Gaussian envelope function. The amplitude contrast ratio is also factored into the final CTF calculation.\n",
    "    \"\"\"\n",
    "    # Convert spherical aberration to Angstroms\n",
    "    spherical_aberration *= 1.0e7\n",
    "    # Constants for electron rest mass energy (mo) in keV and Planck constant times speed of light (hc) in Angstrom-keV\n",
    "    mo = 511.0\n",
    "    hc = 12.3986\n",
    "    # Calculate electron wavelength (wav) in Angstroms\n",
    "    wav = hc / np.sqrt((2 * mo + electron_energy) * electron_energy)\n",
    "    # Precompute terms for the CTF formula\n",
    "    w1 = np.pi * spherical_aberration * wav**3\n",
    "    w2 = np.pi * wav * defocus\n",
    "    k2 = k**2\n",
    "    # Gaussian envelope function\n",
    "    sigm = gauss_env_halfwidth / np.sqrt(2 * np.log(2))\n",
    "    wi = np.exp(-k2 / (2 * sigm**2))\n",
    "    # Phase shift induced by spherical aberration and defocus\n",
    "    wr = (0.5 * w1 * k2 - w2) * k2\n",
    "    # Combine phase shift with amplitude contrast to compute the CTF\n",
    "    return (np.sin(wr) - amplitude_contrast_ratio * np.cos(wr)) * wi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a5345",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LocalInput:\n",
    "    \"\"\"\n",
    "    A class to encapsulate local input data for processing.\n",
    "\n",
    "    Attributes:\n",
    "    - indices (NDArray): A 1D NumPy array of global image indices.\n",
    "    - quats (NDArray): A 2D NumPy array (4xN) of rotation quaternions for all images.\n",
    "    - defocus (NDArray): A 1D NumPy array of defocus values for all images.\n",
    "    - dist_file (str): Path to the output file where results will be stored.\n",
    "\n",
    "    This class is designed to organize input data for image processing tasks, \n",
    "    making it easier to pass multiple related data items as a single object.\n",
    "    \"\"\"\n",
    "\n",
    "    indices: NDArray[Shape[\"*\"], Int]     # Global image indexes\n",
    "    quats: NDArray[Shape[\"4,*\"], Float64] # Rotation quaternions of all images, 4xN\n",
    "    defocus: NDArray[Shape[\"*\"], Float64] # Defocus values of all images\n",
    "    dist_file: str                        # Output file for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a10e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_CTF_local(input_data: LocalInput, filter_params: FilterParams, img_file_name: str,\n",
    "                           image_offsets: Tuple[NDArray[Shape[\"*\"], Float64], NDArray[Shape[\"*\"], Float64]],\n",
    "                           n_particles_tot: int, relion_data: bool):\n",
    "    \"\"\"\n",
    "    This function calculates squared Euclidean distances between images in similar projection directions,\n",
    "    incorporating Contrast Transfer Function (CTF) correction. It handles both original images and their conjugates,\n",
    "    effectively doubling the number of data points for analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - input_data (LocalInput): An object containing indices, quaternions, defocus values, and the output file path.\n",
    "    - filter_params (FilterParams): Parameters for the Gaussian filter, including cutoff frequency and order.\n",
    "    - img_file_name (str): Path to the file containing all raw images.\n",
    "    - image_offsets (tuple): Offsets for each image, typically extracted from STAR files.\n",
    "    - n_particles_tot (int): Total number of particles, including both original and conjugate images.\n",
    "    - relion_data (bool): Flag indicating whether the data format is RELION (True) or another format (False).\n",
    "\n",
    "    The function processes each image based on its index, applying normalization, filtering, and CTF correction.\n",
    "    It aligns images in-plane using calculated psi angles and computes distances between all pairs of images in the\n",
    "    given subset. The results, including distances and other relevant data, are saved to the specified output file.\n",
    "\n",
    "    Note:\n",
    "    The function assumes the presence of several globally defined functions and parameters, such as `annularMask`,\n",
    "    `create_grid`, `quats_to_unit_vecs`, `psi_ang`, `projectMask`, `ctemh_cryoFrank`, `get_wiener1`, and `fout1`,\n",
    "    as well as the `LocalInput` and `FilterParams` classes. These dependencies should be defined elsewhere in the codebase.\n",
    "    \"\"\"\n",
    "    # Extracting necessary data from input_data\n",
    "    indices = input_data.indices\n",
    "    quats = input_data.quats\n",
    "    defocus = input_data.defocus\n",
    "    out_file = input_data.dist_file\n",
    "\n",
    "    # Number of particles in the current subset\n",
    "    n_particles = indices.shape[0]\n",
    "\n",
    "    # Global parameters for image processing\n",
    "    n_pix = p.nPix  # Image dimensions\n",
    "\n",
    "    # Initializing arrays for image processing\n",
    "    img_avg = np.zeros((n_pix, n_pix))  # For storing average image\n",
    "    img_all = np.zeros((n_particles, n_pix, n_pix))  # For storing all processed images\n",
    "    fourier_images = np.zeros((n_particles, n_pix, n_pix), dtype=np.complex128)  # Fourier transform of images\n",
    "    CTF = np.zeros((n_particles, n_pix, n_pix))  # Contrast Transfer Function for each image\n",
    "    distances = np.zeros((n_particles, n_particles))  # To store distances between images\n",
    "\n",
    "    # Creating an annular mask for image processing\n",
    "    msk = annularMask(0, n_pix / 2., n_pix, n_pix)\n",
    "\n",
    "    # Creating a grid for the filter and applying the filter\n",
    "    Q = create_grid(n_pix)\n",
    "    G = filter_params.create_filter(Q)\n",
    "    G = ifftshift(G)  # Shifting the filter for correct application\n",
    "\n",
    "    # Calculating the average orientation vector for in-plane rotation alignment\n",
    "    avg_orientation_vec = np.sum(quats_to_unit_vecs(quats), axis=1)\n",
    "    avg_orientation_vec /= np.linalg.norm(avg_orientation_vec)\n",
    "\n",
    "    # Calculating psi_p angle for in-plane rotation alignment\n",
    "    psi_p = psi_ang(avg_orientation_vec)\n",
    "\n",
    "    # Applying a volumetric mask if available\n",
    "    if p.mask_vol_file:\n",
    "        with mrcfile.open(p.mask_vol_file) as mrc:\n",
    "            mask3D = mrc.data\n",
    "        msk2 = projectMask(mask3D, avg_orientation_vec)\n",
    "    else:\n",
    "        msk2 = 1  # No mask applied if not specified\n",
    "\n",
    "    # Processing each image\n",
    "    for i_part in range(n_particles):\n",
    "        # Determining the index of the particle image to process\n",
    "        if indices[i_part] < n_particles_tot / 2:\n",
    "            raw_particle_index = indices[i_part]\n",
    "        else:\n",
    "            raw_particle_index = (indices[i_part] - n_particles_tot) // 2\n",
    "\n",
    "        # Loading the image\n",
    "        if not relion_data:\n",
    "            start = n_pix**2 * raw_particle_index * 4\n",
    "            img = np.memmap(img_file_name, dtype='float32', offset=start, mode='r', shape=(n_pix, n_pix)).T\n",
    "        else:\n",
    "            img = mrcfile.mmap(img_file_name, 'r').data[raw_particle_index]\n",
    "            shi = (image_offsets[1][raw_particle_index] - 0.5, image_offsets[0][raw_particle_index] - 0.5)\n",
    "            img = shift(img, shi, order=3, mode='wrap')\n",
    "\n",
    "        # Flipping the image for conjugates\n",
    "        if indices[i_part] >= n_particles_tot / 2:\n",
    "            img = np.flipud(img)\n",
    "\n",
    "        # Normalizing the image\n",
    "        backg = img * (1 - msk)\n",
    "        std = backg.std()\n",
    "        if std != 0.:\n",
    "            img = (img - backg.mean()) / std\n",
    "        else:\n",
    "            print(f\"Warning: flat image found at index: {raw_particle_index}\")\n",
    "\n",
    "        # Filtering the image\n",
    "        img = img.flatten('F')\n",
    "        img = img.reshape(-1, n_pix).transpose()\n",
    "        img = ifft2(fft2(img) * G).real.flatten('F')\n",
    "\n",
    "        # Aligning the image in-plane\n",
    "        psi = get_psi(quats[:, i_part], avg_orientation_vec)\n",
    "        if np.isnan(psi):\n",
    "            psi = 0.\n",
    "        img = img.reshape(-1, n_pix).transpose() * msk\n",
    "        img = rotate_fill(img, -(180 / np.pi) * psi)\n",
    "        img = rotate_fill(img, -psi_p)\n",
    "\n",
    "        # Applying CTF correction\n",
    "        ctf_i = ctemh_cryoFrank(Q / (2 * p.pix_size), p.Cs, defocus[i_part], p.EkV, p.gaussEnv, p.AmpContrast)\n",
    "        CTF[i_part, :, :] = ifftshift(ctf_i)\n",
    "\n",
    "        # Storing the Fourier transformed image\n",
    "        fourier_images[i_part, :, :] = fft2(img * msk2)\n",
    "        img_all[i_part, :, :] = img\n",
    "\n",
    "    # Calculating distances using Wiener filter\n",
    "    img_avg = np.mean(img_all, axis=0) * msk2\n",
    "    wiener_dom = get_wiener1(CTF)\n",
    "    for i_part in range(n_particles):\n",
    "        img_f = fft2(img_all[i_part, :, :])\n",
    "        CTF_i = CTF[i_part, :, :]\n",
    "        img_f_wiener = img_f * (CTF_i / wiener_dom)\n",
    "        img_avg += ifft2(img_f_wiener).real\n",
    "\n",
    "    img_avg /= n_particles\n",
    "    fourier_images = fourier_images.reshape(n_particles, n_pix**2)\n",
    "    CTF = CTF.reshape(n_particles, n_pix**2)\n",
    "    CTFfy = CTF.conj() * fourier_images\n",
    "    distances = np.dot((np.abs(CTF)**2), (np.abs(fourier_images)**2).T)\n",
    "    distances += distances.T - 2 * np.real(np.dot(CTFfy, CTFfy.conj().T))\n",
    "\n",
    "    # Saving the results\n",
    "    fout1(out_file, D=distances, ind=indices, q=quats, CTF=CTF, imgAll=img_all, msk2=msk2, PD=avg_orientation_vec, imgAvg=img_avg) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a0280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _construct_input_data(thresholded_indices, quats_full, defocus):\n",
    "    \"\"\"\n",
    "    Constructs a list of LocalInput objects from given indices, quaternions, and defocus values.\n",
    "\n",
    "    Parameters:\n",
    "    - thresholded_indices: A list of arrays, each containing indices of data points that meet a certain criterion.\n",
    "    - quats_full: A 2D array of shape [4, N] containing the rotation quaternions for all data points.\n",
    "    - defocus: A 1D array containing the defocus values for all data points.\n",
    "\n",
    "    Returns:\n",
    "    - A list of LocalInput objects, each initialized with a subset of data points specified by the thresholded indices.\n",
    "\n",
    "    This function iterates over the list of thresholded indices. For each set of indices, it extracts the corresponding\n",
    "    quaternions and defocus values. It then creates a LocalInput object for each set, specifying the output file path\n",
    "    for results using a method `p.get_dist_file(prD)`, which is assumed to generate or retrieve a file path based on\n",
    "    the index `prD`. The resulting list of LocalInput objects is suitable for batch processing or parallel computation\n",
    "    tasks, where each object contains a coherent subset of the overall data.\n",
    "    \"\"\"\n",
    "    ll = []  # Initialize an empty list to hold the LocalInput objects\n",
    "    for prD in range(len(thresholded_indices)):\n",
    "        ind = thresholded_indices[prD]  # Get the indices for the current subset\n",
    "        # Create a LocalInput object with the current subset of indices, quaternions, and defocus values\n",
    "        ll.append(LocalInput(ind, quats_full[:, ind], defocus[ind], p.get_dist_file(prD)))\n",
    "    return ll  # Return the list of LocalInput objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55657b62",
   "metadata": {},
   "source": [
    "## Distance Calculation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5274d",
   "metadata": {},
   "source": [
    "### Step 1: Initialize Parameters and Load Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a63ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the project name to before loading the parameters\n",
    "p.proj_name = project_name\n",
    "# When we call p.load(), it should attempt to load \"params_sample.toml\"\n",
    "p.load()\n",
    "# Print the parameters to verify they are loaded correctly\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9854ec",
   "metadata": {},
   "source": [
    "### Step 2: Data_store class\n",
    "\n",
    "The data_store.get_prds() function and its underlying processes focus on processing and organizing projection direction data derived from particle orientations and defocus values. \n",
    "\n",
    "    1. .star File: The data_store.get_prds() function uses the .star file. The .star file in cryo-EM contains metadata about the micrographs or particle picks, including alignment parameters (Euler angles for rotation, tilt, and psi), defocus values (DefocusU, DefocusV), and the origins (shifts) of particles. This information is crucial for determining the projection directions of particles. The get_align_data() function extracts this alignment and defocus information from the .star file to compute the quaternions and other necessary parameters for further analysis.\n",
    "\n",
    "    2. .mrcs File: The .mrcs file contains the particle images (stacks of 2D projections of the 3D structure). While the data_store.get_prds() function itself does not directly process the .mrcs file, the particle orientations of the images and defocus values extracted from the .star file correspond to these images. The .mrcs file is crucial for other steps in the analysis pipeline, such as image processing and reconstruction, but not directly used in calculating projection directions.\n",
    "\n",
    "    3. .mrc File: The .mrc file contains 3D volumes or reconstructions in cryo-EM. The avg_vol_file parameter, which points to an .mrc file, is used in other parts of the analysis for tasks like volume rendering, filtering, or comparison against projections. However, the .mrc file is not directly used in the data_store.get_prds() function for calculating projection directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a214f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load projection direction data\n",
    "prds = data_store.get_prds()\n",
    "print(\"Projection direction data:\", prds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0374f63",
   "metadata": {},
   "source": [
    "### Step 3: Set filter parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8616d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_params = FilterParams(method='Butter', cutoff_freq=0.5, order=8)\n",
    "print(\"Filter parameters:\", filter_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8d9a75",
   "metadata": {},
   "source": [
    "### Step 4: Prepare input data through _construct_ input_data\n",
    "\n",
    "The _construct_input_data function is designed to prepare input data for further processing, specifically for calculating distances between images based on their projection directions, quaternions, and defocus values.\n",
    "\n",
    "    1. Parameters\n",
    "\n",
    "        1. thresholded_indices: A list or array of indices that have been selected based on the thresholding criteria. These indices represent a subset of the total data that meets certain conditions.\n",
    "        2. quats_full: A 2D array where each column represents the quaternion associated with an image. Quaternions are a compact way to represent rotations in three dimensions.\n",
    "        3. defocus: An array containing the defocus values for each image. Defocus is a parameter that affects the contrast and resolution of images in electron microscopy.\n",
    "\n",
    "    2. Process\n",
    "\n",
    "        1. Initialization: The function initializes an empty list ll to store the prepared input data.\n",
    "        2. Loop Over Thresholded Indices: For each index in thresholded_indices, the function performs the following steps:\n",
    "        \n",
    "        (a) Retrieves the corresponding quaternion from quats_full using the current index. Since quats_full is a 2D array where columns represent quaternions, it selects the entire column corresponding to the current index.\n",
    "        \n",
    "        (b) Retrieves the defocus value for the current index from the defocus array.\n",
    "        \n",
    "        (c) Constructs a LocalInput object with the current index, the selected quaternion, the defocus value, and a distance file path obtained from p.get_dist_file(prD). The LocalInput class is not defined in the provided snippets but is assumed to be a data structure designed to hold these pieces of information for processing. It then appends the constructed LocalInput object to the list ll.\n",
    "\n",
    "    3. Return : After iterating through all indices in thresholded_indices, the function returns the list ll containing all the prepared LocalInput objects.\n",
    "\n",
    "    4. Return Value: The function returns a list of LocalInput objects, each containing the necessary data (index, quaternion, defocus value, and distance file path) for further processing, such as calculating distances between images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0504c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = _construct_input_data(prds.thresholded_image_indices, \n",
    "                                   prds.quats_full, prds.defocus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62fae12",
   "metadata": {},
   "source": [
    "#### Input data for distance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ccb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(input_data[0], '__dict__'):\n",
    "    # If the instance has a __dict__ attribute, print its keys\n",
    "    print(vars(input_data[0]).keys())\n",
    "elif isinstance(input_data[0], dict):\n",
    "    # If the instance itself is a dictionary\n",
    "    print(input_data[0].keys())\n",
    "else:\n",
    "    # If LocalInput uses a method to return its attributes as a dictionary\n",
    "    # Assuming the method is named 'to_dict()'\n",
    "    print(input_data[0].to_dict().keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ac02df",
   "metadata": {},
   "source": [
    "### Step 5: Distance calculation set up\n",
    "\n",
    "This step involves setting up the infrastructure for parallel computation of distances between images, incorporating corrections for the Contrast Transfer Function (CTF).\n",
    "\n",
    "    1. Parameters\n",
    "    \n",
    "        (a) input_data: A collection of data structures (e.g., LocalInput instances) prepared in the previous step. Each element represents a set of images grouped by similar projection directions, along with their associated quaternions and defocus values.\n",
    "\n",
    "        (b) filter_params: Parameters for the image filtering process, which include specifications for Gaussian or Butterworth filters. \n",
    "\n",
    "        (c) img_file_name: The path to the file containing the stack of images. This file is accessed to retrieve individual images based on their indices during the distance calculation process.\n",
    "\n",
    "        (d) image_offsets: The origins of the images, derived from microscope settings. These offsets are essential for accurately applying CTF corrections.\n",
    "        \n",
    "        (e) n_particles_tot: The total number of particles (images) in the dataset. This information is used to handle datasets where images and their conjugates are considered to augment the data.\n",
    "\n",
    "        (f) relion_data: A flag indicating whether the dataset follows the data format used by RELION, a software package for cryo-electron microscopy data analysis. This affects how images are read and processed.\n",
    "\n",
    "    2. Process\n",
    "    \n",
    "        (a) Determine the Number of Jobs: The variable n_jobs is calculated as the length of input_data, indicating how many separate sets of images will be processed in parallel.\n",
    "\n",
    "        (b) Define Local Distance Function: The partial function from the functools module is utilized to create a version of the get_distance_CTF_local function with some arguments pre-filled. This technique simplifies the function call syntax when executing parallel computations. The predefined arguments include filter_params, img_file_name, image_offsets, n_particles_tot, and relion_data, leaving input_data as the only variable argument during execution.\n",
    "\n",
    "    3. Return Value: The setup process does not return a value directly but prepares the local_distance_func for subsequent parallel execution. This function, now equipped with the necessary context for processing a specific subset of the data, is ready to be called with varying input_data for each job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbaba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of jobs\n",
    "n_jobs = len(input_data)\n",
    "print(\"n_jobs:\", n_jobs )\n",
    "# Define the local distance function with predefined arguments\n",
    "local_distance_func = partial(get_distance_CTF_local,\n",
    "                              filter_params=filter_params,\n",
    "                              img_file_name=p.img_stack_file,\n",
    "                              image_offsets=prds.microscope_origin,\n",
    "                              n_particles_tot=len(prds.defocus),\n",
    "                              relion_data=p.relion_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecff6747",
   "metadata": {},
   "source": [
    "### Step 6: Executing distance calculation \n",
    "\n",
    "This step involves the execution of distance calculations for each set of images grouped by similar projection directions. The process iterates over input_data, which contains prepared data structures (e.g., LocalInput instances) for each group of images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d03ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, datai in tqdm.tqdm(enumerate(input_data), total=n_jobs):\n",
    "    local_distance_func(datai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c74acc3",
   "metadata": {},
   "source": [
    "### Step 7: Save parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769a304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.save()\n",
    "print(\"Parameters saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65834b1a",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414e6c14",
   "metadata": {},
   "source": [
    "### Step 1: Initialize Parameters and Load Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7331d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_and_load_parameters(project_name):\n",
    "    \"\"\"\n",
    "    Initializes parameters for a given project and loads existing data from a TOML file.\n",
    "    \n",
    "    Parameters:\n",
    "    - project_name (str): The name of the project for which parameters are to be loaded.\n",
    "    \"\"\"\n",
    "    # Ensure the 'p' module/class is available with required attributes and methods\n",
    "    if not hasattr(p, 'proj_name') or not hasattr(p, 'load'):\n",
    "        print(\"Error: The 'p' module/class does not have the required attributes/methods.\")\n",
    "        return\n",
    "    \n",
    "    # Set the project name before loading the parameters\n",
    "    p.proj_name = project_name\n",
    "    \n",
    "    try:\n",
    "        # Attempt to load parameters from the TOML file associated with the project name\n",
    "        p.load()\n",
    "        # If loading is successful, print the loaded parameters\n",
    "        print(\"Loaded parameters:\")\n",
    "        print(p)\n",
    "    except Exception as e:\n",
    "        # Handle exceptions that may occur during parameter loading, such as file not found\n",
    "        print(f\"Error loading parameters for project '{project_name}': {e}\")\n",
    "\n",
    "initialize_and_load_parameters(project_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f21a8",
   "metadata": {},
   "source": [
    "### Step 2  : Obtaining the Projection Direction Data\n",
    "\n",
    "The data_store.get_prds() function call is a crucial part of the manifold analysis process, specifically designed for loading or calculating projection direction data. \n",
    "\n",
    "### Overview\n",
    "\n",
    "The data_store object is an instance of a singleton class designed to manage and provide access to the projection direction data and related analysis parameters. The data_store.get_prds() function is a method of the _DataStore class that retrieves projection direction data for further analysis. This method primarily interacts with the _ProjectionDirections class, which is responsible for managing and calculating the projection direction data.\n",
    "\n",
    "### Detailed Breakdown\n",
    "\n",
    "#### Singleton Pattern\n",
    "The _DataStore class uses a singleton pattern to ensure that there is only one instance of the data store throughout the application. This pattern is useful for managing global states, like the projection direction data, which needs to be consistently accessible from different parts of the program.\n",
    "\n",
    "#### Retrieve or Calculate Projection Directions\n",
    "When data_store.get_prds() is called, it checks if the projection direction data (prds) is already available. If not, it proceeds to calculate this data. The update() method in _ProjectionDirections checks if the projection direction data is already loaded. If not, it calculates this data. If a data file exists (p.pd_file), the method attempts to load the projection direction data from this file. If the data is not loaded or needs to be recalculated, the method proceeds to calculate the projection direction data.\n",
    "\n",
    "#### Projection Direction Calculation\n",
    "\n",
    "The calculation involves several steps, including:\n",
    "\n",
    "    1. Reading alignment parameters from a .star file, which includes information about the orientations of the particles and its positions.\n",
    "\n",
    "    2. Binning and thresholding projection directions based on their occupancy, which helps in reducing the complexity of the data and focusing on the most relevant directions for analysis.\n",
    "\n",
    "    3. Augmenting the data by considering both original and conjugate projection directions to ensure comprehensive coverage of the orientation space.\n",
    "\n",
    "Functions called are as under: \n",
    "\n",
    "    1. distribute3Sphere(numPts): Distributes points uniformly on a unit 3-sphere. This function is crucial for creating bin centers in a uniform distribution across the sphere.\n",
    "\n",
    "    2. quaternion_to_S2(q): Converts quaternions to S2 coordinates. This transformation is essential for mapping particle orientations to points on the unit sphere.\n",
    "\n",
    "    3. collect_nearest_neighbors(X, Q): Finds the nearest neighbors for points on the unit sphere. This function helps in binning the orientations based on their spatial distribution.\n",
    "\n",
    "    4. bin_and_threshold(q, bin_width, thres_low, thres_high): Bins the orientations and applies thresholding to filter out bins with too few or too many orientations.\n",
    "\n",
    "    5. augment(q): Augments the dataset by creating conjugate quaternions, effectively doubling the number of data points.\n",
    "\n",
    "#### Projection Directions (prds) Structure\n",
    "\n",
    "The prds object contains several important pieces of information, including:\n",
    "\n",
    "    1. bin_centers: The coordinates of the projection directions on the unit sphere.\n",
    "\n",
    "    2. defocus: Defocus values associated with each projection direction.\n",
    "\n",
    "    3. quats_full: Quaternion representations of the orientations of particles.\n",
    "\n",
    "    4. thresholded_image_indices: Indices of images that meet certain occupancy thresholds, which are used for further analysis.\n",
    "\n",
    "    5. occupancy_full: The number of particles associated with each projection direction.\n",
    "\n",
    "#### Visualization and Analysis\n",
    "\n",
    "The projection direction data can be visualized as points on a unit sphere to understand the distribution of particle orientations in the dataset. This visualization is crucial for ensuring that the data covers the orientation space adequately and for identifying any potential biases or gaps in coverage.\n",
    "\n",
    "#### Further Processing\n",
    "\n",
    "After obtaining the prds data, it is used for various processing steps, such as calculating distances between particles based on their orientations and defocus values. These distances form the basis for constructing a manifold that represents the high-dimensional structure of the dataset in a lower-dimensional space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3bb278",
   "metadata": {},
   "source": [
    "### Step 2A: Get projection direction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713857b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prds = data_store.get_prds()\n",
    "print(\"Projection direction data:\", prds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3135d1",
   "metadata": {},
   "source": [
    "### Step 2B: Look into the projection data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242a099",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data = p.pd_file\n",
    "with open(pd_data, 'rb') as file:\n",
    "    projection_dir_data = pickle.load(file)\n",
    "print(projection_dir_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437cab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptions for each key\n",
    "descriptions = {\n",
    "    'thres_low': 'The lower threshold for filtering projection directions based on occupancy.',\n",
    "    'thres_high': 'The upper threshold for filtering projection directions based on occupancy.',\n",
    "    'bin_centers': 'Coordinates of the projection directions on the unit sphere.',\n",
    "    'defocus': 'Defocus values associated with each projection direction.',\n",
    "    'microscope_origin': 'Origin coordinates of the microscope.',\n",
    "    'pos_full': 'Full position data for projection directions.',\n",
    "    'quats_full': 'Quaternion representations of the orientations of particles.',\n",
    "    'image_indices_full': 'Indices of images that meet certain occupancy thresholds.',\n",
    "    'thres_ids': 'Indices of projection directions that meet the threshold criteria.',\n",
    "    'occupancy_full': 'The number of particles associated with each projection direction.',\n",
    "    'anchors': 'Anchor points with associated properties.',\n",
    "    'trash_ids': 'Set of IDs marked for exclusion or deletion.',\n",
    "    'reembed_ids': 'Set of IDs marked for re-embedding in the analysis.',\n",
    "    'neighbor_graph': 'Graph representing neighborhood relationships between projection directions.',\n",
    "    'neighbor_subgraph': 'List of subgraphs derived from the neighbor graph.',\n",
    "    'neighbor_graph_pruned': 'Pruned version of the neighbor graph.',\n",
    "    'neighbor_subgraph_pruned': 'List of pruned subgraphs derived from the neighbor graph.',\n",
    "    'pos_thresholded': 'Position data for projection directions after thresholding.',\n",
    "    'theta_thresholded': 'Theta angles for thresholded projection directions.',\n",
    "    'phi_thresholded': 'Phi angles for thresholded projection directions.',\n",
    "    'cluster_ids': 'Cluster IDs assigned to projection directions based on connectivity.'\n",
    "}\n",
    "\n",
    "def print_projection_direction_details(data):\n",
    "    for key, value in data.items():\n",
    "        print(f\"{key}: {descriptions[key]}\")\n",
    "        if hasattr(value, 'shape'):\n",
    "            # If the value is a numpy array, print its shape\n",
    "            print(f\"    Shape = {value.shape}\")\n",
    "        elif isinstance(value, (list, dict, set)):\n",
    "            # If the value is a list, dict, or set, print its length\n",
    "            print(f\"    Length = {len(value)}\")\n",
    "        else:\n",
    "            # For other types, print the value directly\n",
    "            print(f\"    Value = {value}\")\n",
    "        print()  # Print a newline for better readability\n",
    "\n",
    "print_projection_direction_details(projection_dir_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e605cf",
   "metadata": {},
   "source": [
    "### Overview of the projection direction data\n",
    "\n",
    "\n",
    "    1. Initially, the dataset contains information related to a total of 28,982 projection directions. This is indicated by the shape of the defocus array and the pos_full and quats_full arrays, which all have lengths corresponding to 28,982, representing the total number of projection directions (or particles) for which data is available.\n",
    "\n",
    "    2. The image_indices_full array, with a shape of (4071,), suggests that there are 4,071 unique projection directions that meet certain occupancy thresholds. This means that out of the initial set of projection directions, 4,071 were identified as having a significant number of particles associated with them, based on the occupancy thresholds defined by thres_low and thres_high.\n",
    "\n",
    "    3. After applying further filtering and thresholding criteria, the thres_ids array, with a length of 63, indicates that 63 projection directions were selected for further analysis. These projection directions meet the threshold criteria and are considered significant for the reconstruction or analysis process. The pos_thresholded, theta_thresholded, and phi_thresholded arrays, all related to these 63 projection directions, provide the spatial coordinates and angles for these selected directions.\n",
    "\n",
    "In summary:\n",
    "\n",
    "    1. Initially, there were data for 28,982 projection directions (or particles).\n",
    "    2. After applying occupancy thresholds, 4,071 unique projection directions were identified.\n",
    "    3. Finally, after further filtering, 63 projection directions were selected for detailed analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9adf35",
   "metadata": {},
   "source": [
    "### Distributon of bin centers in 3D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c0f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = projection_dir_data['bin_centers'] \n",
    "print(\"Number of bin centers:\", len(projection_dir_data['bin_centers'][0]))\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "fig.patch.set_facecolor('white')  \n",
    "ax.patch.set_facecolor('white')   \n",
    "ax.scatter(x, y, z, marker='o', s=0.5, color='black')  \n",
    "ax.set_xlabel('X', labelpad=5)\n",
    "ax.set_ylabel('Y', labelpad=5)\n",
    "ax.set_zlabel('Z', labelpad=0)  \n",
    "plt.title('Distribution of Bin Centers in 3D Space')\n",
    "ax.grid(False)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de282c1",
   "metadata": {},
   "source": [
    "### Distributon of S2 coordinates in 3D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa658e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = projection_dir_data['pos_full']\n",
    "print(\"Number of particles:\", len(projection_dir_data['pos_full'][0]))\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "fig.patch.set_facecolor('white')  \n",
    "ax.patch.set_facecolor('white')\n",
    "ax.scatter(x, y, z, marker='o', s=0.5, color='black')\n",
    "ax.set_xlabel('X', labelpad=5)\n",
    "ax.set_ylabel('Y', labelpad=5)\n",
    "ax.set_zlabel('Z', labelpad=0)  \n",
    "plt.title('Distributon of S2 coordinates in 3D space')\n",
    "u, v = np.mgrid[0:2*np.pi:100j, 0:np.pi:50j]\n",
    "xs = np.cos(u)*np.sin(v)\n",
    "ys = np.sin(u)*np.sin(v)\n",
    "zs = np.cos(v)\n",
    "ax.plot_wireframe(xs, ys, zs, color=\"k\", alpha=0.05)\n",
    "ax.grid(False)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming selected_occupancy contains the occupancy data for the selected projection directions\n",
    "occupancy_full = projection_dir_data['occupancy_full']\n",
    "thres_ids = projection_dir_data['thres_ids']\n",
    "selected_occupancy = occupancy_full[thres_ids]\n",
    "\n",
    "# Indices for the first two, middle two, and last two projection directions\n",
    "first_two_indices = [0, 1]\n",
    "middle_two_indices = [len(selected_occupancy)//2 - 1, len(selected_occupancy)//2]\n",
    "last_two_indices = [-2, -1]\n",
    "\n",
    "# Print the number of particles for the first two, middle two, and last two projection directions\n",
    "print(\"First two projection directions:\")\n",
    "for i in first_two_indices:\n",
    "    print(f\"Projection Direction {thres_ids[i]+1}: {selected_occupancy[i]} particles\")\n",
    "\n",
    "print(\"\\nMiddle two projection directions:\")\n",
    "for i in middle_two_indices:\n",
    "    print(f\"Projection Direction {thres_ids[i]+1}: {selected_occupancy[i]} particles\")\n",
    "\n",
    "print(\"\\nLast two projection directions:\")\n",
    "for i in last_two_indices:\n",
    "    print(f\"Projection Direction {thres_ids[i]+1}: {selected_occupancy[i]} particles\")\n",
    "\n",
    "# Calculate and print the total number of particles in selected projection directions\n",
    "total_particles_in_selected_directions = selected_occupancy.sum()\n",
    "print(f\"\\nTotal number of particles in selected projection directions: {total_particles_in_selected_directions}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6944fd3c",
   "metadata": {},
   "source": [
    "### Step 2C: Understand some of the helper functions\n",
    "\n",
    "To break down the get_prds() process for step-by-step execution, we can follow these steps. Each step will correspond to a part of the code that contributes to the overall process of generating and organizing projection direction data. \n",
    "\n",
    "    Step 1: Initialize Parameters and Load Existing Data: Before calling get_prds(), we ensure that the parameters in params.py are correctly set according to the requirements of the project.\n",
    "\n",
    "    Step 2: Check for Existing Projection Direction Data: Check if there is existing data to avoid recalculating everything. This step is encapsulated in the load method of _ProjectionDirections.\n",
    "\n",
    "    Step 3: Parse Alignment Data from .star File: Extract alignment parameters and defocus values from the .star file. This involves reading the file and parsing relevant data.\n",
    "\n",
    "    Step 4: Augment Data and Calculate S2 Cordinates: Augment the quaternion data to account for symmetry and calculate the S2 coordinates for projection directions.\n",
    "\n",
    "    Step 5: Bin and Threshold Projection Directions: Organize projection directions into bins and apply thresholding based on occupancy.\n",
    "\n",
    "    Step 6: Visualize Projection Directions: Visualize the projection directions on a unit sphere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5bd42",
   "metadata": {},
   "source": [
    "### (i) Parse alignment data from .star file\n",
    "\n",
    "The parse_alignment_data() function extracts and returns four key quantities from an alignment parameter file (a .star file).\n",
    "\n",
    "    1. sh (Shifts): This is a tuple containing two arrays, shx and shy, which represent the shifts in the X and Y directions, respectively, for each particle or image. These shifts are used to align the images correctly, compensating for any translational movement that occurred during image capture.\n",
    "\n",
    "    2. q (Quaternions): Quaternions are a way to represent rotations in 3D space. This array contains the quaternion representation of the orientation for each particle or image. Quaternions are preferred over Euler angles in many 3D computations because they are not susceptible to gimbal lock and can represent rotations more compactly and robustly.\n",
    "\n",
    "    3. U and V (Defocus Values): These are arrays containing the defocus values along two principal axes for each particle or image. In the context of electron microscopy, defocus is used intentionally to enhance contrast, but it varies across images. The U and V values represent the major and minor axes of an elliptical approximation of the defocus of the lens, indicating how much the electron beam is defocused when it hits the specimen. These values are crucial for reconstructing the 3D structure from 2D images by compensating for the phase shifts introduced by defocus.\n",
    "\n",
    "The parse_alignment_data() function processes the alignment file to extract these parameters, which are then used in subsequent steps of image processing and 3D reconstruction workflows. The shifts and defocus values are directly extracted from the .star file, while the quaternions are calculated from the Euler angles (also provided in the .star file) using the eul_to_quat() function, which converts Euler angles to quaternion representation. This conversion is necessary because the alignment data in the .star file is typically given in terms of Euler angles (rlnAngleRot, rlnAngleTilt, rlnAnglePsi), which describe the rotation of each particle or image in 3D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ee6db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_alignment_data():\n",
    "    sh, q, U, V = get_align_data(p.align_param_file, flip=True)\n",
    "    print(\"Alignment data parsed.\")\n",
    "    return sh, q, U, V\n",
    "\n",
    "sh, q, U, V = parse_alignment_data()\n",
    "print(\"The length of x shifts is :\" + str(len(list(sh[0]))))\n",
    "print(\"The length of y shifts is :\" + str(len(list(sh[1]))))\n",
    "print(\"The shape of shifts is : [\" + str(len(list(sh[0]))) +  \",2]\")\n",
    "print(\"The shape of quaternion is :\" + str(q.shape))\n",
    "print(\"Quaternions are as follow:\")\n",
    "print(q)\n",
    "print(\"The shape of Defocus Major is :\" + str(U.shape))\n",
    "print(\"The shape of Defocus Minor is :\" + str(V.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9b8bfa",
   "metadata": {},
   "source": [
    "### (ii) Augment Data and Calculate S2 Cordinates\n",
    "\n",
    "    1. S2 refers to the 2-dimensional sphere, which is the set of all points in 3-dimensional space that are at a fixed distance (radius) from a central point. Mathematically, S2 can be defined as:\n",
    "\n",
    "    S2 = {(x, y, z) in R^3 : x^2 + y^2 + z^2 = r^2\n",
    "\n",
    "    where r is the radius of the sphere, and R^3 denotes the 3-dimensional Euclidean space.\n",
    "\n",
    "    2. quaternion_to_S2(q) transforms quaternion representations of orientations into points on the unit sphere S2. Quaternions are a way to encode rotation in 3D space, and converting them to points on S2 is a way to visualize or work with these rotations in terms of directional vectors on a sphere. This conversion simplifies dealing with the distribution of orientations or projection directions in 3D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252e26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_and_calculate_S2_coordinates(q):\n",
    "    q_augmented = augment(q)\n",
    "    S2_coords = quaternion_to_S2(q_augmented)\n",
    "    print(\"Data augmented and projection directions calculated.\")\n",
    "    return S2_coords\n",
    "S2_coords = augment_and_calculate_S2_coordinates(q)\n",
    "print(\"The shape of S2_coords is :\" + str(S2_coords.shape))\n",
    "print(\"S2_coords are as follow:\")\n",
    "print(S2_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fa599",
   "metadata": {},
   "source": [
    "### (iii) Bin and Threshold Projection Directions\n",
    "\n",
    "The function bin_and_threshold_projection_directions (q_augmented) organizes the augmented quaternion data into bins based on their projection directions and applies thresholds to filter out bins based on the number of orientations they contain. Here's an explanation of the output quantities:\n",
    "\n",
    "    1. neighb_list: This is a list where each element corresponds to a bin of projection directions. Each element of neighb_list contains the indices of the q_augmented data points that belong to that bin. This list helps in understanding how the orientations are distributed across different bins.\n",
    "\n",
    "    2. S2: This array represents the coordinates of the projection directions on the unit sphere S2 after mapping the augmented quaternion data. Each column in S2 corresponds to a point on the unit sphere, representing a unique orientation in three-dimensional space.\n",
    "\n",
    "    3. bin_centers: This array contains the coordinates of the centers of the bins on the unit sphere S2. Each column in bin_centers represents the center of a bin, essentially summarizing the orientation of all the projection directions within that bin. The binning process aims to cover the sphere uniformly, so these centers are distributed to achieve as uniform coverage as possible given the binning strategy.\n",
    "\n",
    "    4. n_points_in_bin: This array contains the number of points (or orientations) in each bin. It allows for the application of thresholds to filter bins based on their occupancy, ensuring that bins with too few or too many points are handled appropriately (e.g., ignored or further processed).\n",
    "\n",
    "    5. conjugate_bins: This list contains the indices of bins that have passed the thresholding criteria (i.e., bins that contain a number of points within the specified thres_low and thres_high range). These bins are considered significant and contribute to further analysis, such as identifying distinct projection directions for reconstruction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3578ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_and_threshold_projection_directions(q_augmented):\n",
    "    bin_width = p.ang_width\n",
    "    thres_low, thres_high = p.PDsizeThL, p.PDsizeThH\n",
    "    neighb_list, S2, bin_centers, n_points_in_bin, conjugate_bins = bin_and_threshold(q_augmented, bin_width, \n",
    "                                                                                      thres_low, thres_high)\n",
    "    print(\"Projection directions binned and thresholded.\")\n",
    "    return neighb_list, S2, bin_centers, n_points_in_bin, conjugate_bins\n",
    "\n",
    "q_augmented = augment(q)\n",
    "neighb_list, S2, bin_centers, n_points_in_bin, conjugate_bins = bin_and_threshold_projection_directions(q_augmented)\n",
    "print(\"The shape of neighb_list is :\" + str(neighb_list.shape))\n",
    "print(\"Total number of projection directions across all bins:\", str(sum(len(bin) for bin in neighb_list)))\n",
    "print(\"The shape of S2 is :\" + str(S2.shape))\n",
    "print(\"The shape of bin_centers is :\" + str(bin_centers.shape))\n",
    "print(\"The length of conjugate_bins (Indices of bins that have more than thres_low points and are in the bigger half of the bin list) is :\" + str(len(conjugate_bins)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c353b",
   "metadata": {},
   "source": [
    "### (iv) Map Clusters to Quaternions\n",
    "\n",
    "To map which augmented quaternion data points belong to which bin and create a dictionary that represents this mapping, we can use the neighb_list which contains the indices of q_augmented data points for each bin. The keys of this dictionary will be the bin indices, and the values will be lists of indices of q_augmented data points that belong to those bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc1fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_clusters_to_quaternions(q_augmented, neighb_list):\n",
    "    \"\"\"\n",
    "    Maps non-empty clusters to their corresponding quaternion data.\n",
    "    \n",
    "    Parameters:\n",
    "    q_augmented (np.ndarray): The augmented quaternion data array of shape (4, N).\n",
    "    neighb_list (np.ndarray): An array of arrays, where each sub-array contains the indices of q_augmented data points that belong to a specific bin.\n",
    "    \n",
    "    Returns:\n",
    "    dict: A dictionary where keys are non-empty cluster indices and values are the quaternion data points that belong to those clusters.\n",
    "    \"\"\"\n",
    "    cluster_to_quaternions = {}\n",
    "    for cluster_index, data_point_indices in enumerate(neighb_list):\n",
    "        if len(data_point_indices) > 0:  # Exclude empty clusters\n",
    "            # Retrieve the actual quaternion data points for the current cluster\n",
    "            quaternions = q_augmented[:, data_point_indices]\n",
    "            cluster_to_quaternions[cluster_index] = quaternions.T \n",
    "    return cluster_to_quaternions\n",
    "\n",
    "cluster_to_quaternions_mapping = map_clusters_to_quaternions(q_augmented, neighb_list)\n",
    "print (\"There are \" + str(len(cluster_to_quaternions_mapping)) + \" non-empty clusters out of a total of \" + str(neighb_list.shape[0]) + \" bins.\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9ae60",
   "metadata": {},
   "source": [
    "### (v) Plot S2 clusters onto 3D sphere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ebc6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_S2_clusters_on_3D(cluster_to_quaternions_mapping):\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d', facecolor='white')\n",
    "    # Draw a sphere\n",
    "    u = np.linspace(0, 2 * np.pi, 100)\n",
    "    v = np.linspace(0, np.pi, 100)\n",
    "    x = np.outer(np.cos(u), np.sin(v))\n",
    "    y = np.outer(np.sin(u), np.sin(v))\n",
    "    z = np.outer(np.ones(np.size(u)), np.cos(v))\n",
    "    ax.plot_surface(x, y, z, rstride=5, cstride=5, color='white', alpha=0.10, linewidth=0)\n",
    "    \n",
    "    # Get the total number of clusters for color mapping\n",
    "    num_clusters = len(cluster_to_quaternions_mapping)\n",
    "    colors = cm.rainbow(np.linspace(0, 1, num_clusters))\n",
    "    \n",
    "    # Plot each cluster\n",
    "    cluster_index = 0\n",
    "    for cluster_id, quaternions in cluster_to_quaternions_mapping.items():\n",
    "        if quaternions.size == 0:\n",
    "            continue  # Skip empty clusters\n",
    "        S2_coords = quaternion_to_S2(quaternions.T)  # Transpose to match expected shape (4, N)\n",
    "        xs = S2_coords[0, :]\n",
    "        ys = S2_coords[1, :]\n",
    "        zs = S2_coords[2, :]\n",
    "        ax.scatter(xs, ys, zs, color=colors[cluster_index], s=5)\n",
    "        cluster_index += 1\n",
    "    \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    plt.title('Quaternion Clusters on S2 Sphere')\n",
    "    ax.grid(False)  # Disable the grid\n",
    "    \n",
    "    # Colorbar setup\n",
    "    cbar = fig.colorbar(cm.ScalarMappable(norm=plt.Normalize(vmin=1, vmax=num_clusters), cmap=cm.rainbow),\n",
    "                        ax=ax, pad=0.1, fraction=0.02)\n",
    "    \n",
    "    # Set specific tick positions and labels\n",
    "    tick_positions = [1, num_clusters // 2, num_clusters]  # Start, middle, end\n",
    "    cbar.set_ticks(tick_positions)\n",
    "    cbar.set_ticklabels([f'Cluster {tick}' for tick in tick_positions])\n",
    "    \n",
    "    cbar.ax.invert_yaxis()  # Optional: Invert color bar axis if needed\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_S2_clusters_on_3D(cluster_to_quaternions_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d495f806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjugate S2 clusters onto 3D sphere\n",
    "neighb_conjugate_list = []\n",
    "for i in conjugate_bins:\n",
    "    neighb_conjugate_list.append(neighb_list[i])\n",
    "    \n",
    "cluster_to_quaternions_mapping = map_clusters_to_quaternions(q_augmented, neighb_conjugate_list)\n",
    "print (\"There are \" + str(len(cluster_to_quaternions_mapping)) + \" conjugate clusters out of a total of \" + str(neighb_list.shape[0]) + \" bins.\" )\n",
    "plot_S2_clusters_on_3D(cluster_to_quaternions_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e372f8",
   "metadata": {},
   "source": [
    "The get_distance_CTF_local function is designed to calculate squared Euclidean distances between images (snapshots) that are in similar projection directions, incorporating corrections for the Contrast Transfer Function (CTF) of the microscope. This involves several steps, including image normalization, Fourier transformation, application of the Contrast Transfer Function (CTF), and distance calculation.\n",
    "\n",
    "    1. Initialization: The function starts by extracting necessary data from the input_data parameter and initializing various arrays for storing processed images, Fourier transforms of images, CTFs, and distances.\n",
    "\n",
    "    2. Image Processing Loop: For each particle in the given bin (n_particles):\n",
    "\n",
    "        (a) It determines whether the image comes from the original dataset or its augmented version (conjugates).\n",
    "        (b) Reads the corresponding image from the file, applying any necessary shifts based on image_offsets. If the image is from the augmented dataset, it is flipped vertically.\n",
    "        (c) The image is normalized using the background standard deviation and mean.\n",
    "        (d) The image is then flattened, Fourier transformed, and filtered using a Gaussian filter (G).\n",
    "\n",
    "    3. Orientation and CTF Calculation:\n",
    "\n",
    "        (a) The average orientation vector for the bin is calculated from the quaternions.\n",
    "        (b) The psi angle for in-plane rotation alignment is determined.\n",
    "        (c) The Contrast Transfer Function (CTF) for each particle is calculated based on its defocus value and other microscope parameters.\n",
    "\n",
    "    4. Image Averaging and Wiener Filtering: A Wiener filter domain is calculated from the CTFs. Each particle image is Fourier transformed, Wiener filtered, and then averaged to produce a single average image for the bin.\n",
    "\n",
    "    5. Distance Calculation: Using the Fourier-transformed images and their CTFs, the function calculates squared Euclidean distances between all pairs of images, incorporating CTF correction. This involves Wiener filtering to account for noise and improve accuracy.\n",
    "\n",
    "    6. Output: The calculated distances, along with other relevant data (e.g., indices, quaternions, CTFs, images), are saved to an output file specified by out_file.\n",
    "\n",
    "At the end of the get_distance_CTF_local calculations, the saved data includes:\n",
    "\n",
    "    (a) Distances: A matrix of squared Euclidean distances among the particles within the same bin. These distances take into account the CTF correction, providing a measure of similarity between particles that is adjusted for the imaging conditions of the microscope.\n",
    "\n",
    "    (b) Indices: The indices of the particles within the bin. These indices refer to the positions of the particles in the original dataset, allowing for easy reference back to the specific particles being analyzed.\n",
    "\n",
    "    (c) Quaternions (quats): The orientations of the particles represented as quaternions. These orientations are crucial for understanding the relative angles and positions of the particles within their bin.\n",
    "\n",
    "    (d) CTF: The Contrast Transfer Function for each particle. The CTF matrix contains the CTF values that have been applied to each particle image, which are essential for understanding how the imaging process affects the observed particle images.\n",
    "\n",
    "    (e) Image Data (imgAll): The processed images of the particles. This might include images that have been filtered, normalized, and aligned based on the average orientation vector and the CTF correction.\n",
    "\n",
    "    (f) Mask (msk2): If a volumetric mask was used during processing, this data includes the projection of that mask onto the images, which can affect the computed distances by focusing the comparison on specific regions of the particles.\n",
    "\n",
    "    (g) Average Orientation Vector (PD): The average orientation vector for the particles within the bin, providing a reference direction that summarizes the common orientation of the particles.\n",
    "\n",
    "    (h) Average Image (imgAvg): The average image computed from the Fourier-transformed images with Wiener filtering applied. This average image represents a consensus view of the particles within the bin, adjusted for the effects of the CTF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2bc720",
   "metadata": {},
   "source": [
    "### The annularMask function\n",
    "\n",
    "The annularMask function generates an annular (donut-shaped) mask of a specified inner radius a and outer radius b for an N x M matrix. This mask is used in image processing tasks, particularly in fields like cryo-electron microscopy, to focus analyses or operations on specific regions of an image while ignoring others. The mask consists of values set to 1 for pixels within the specified annular region and 0 for pixels outside this region, effectively creating a \"donut\" shape centered on the pixel located at (N/2, M/2).\n",
    "\n",
    "    1. It initializes a zero matrix of size N x M.\n",
    "    2. It iterates through each pixel in the matrix, calculating the distance of each pixel from the center (N/2, M/2).\n",
    "    3. If the squared distance of a pixel from the center is within the range defined by the squared inner radius aSq and the squared outer radius bSq, the function sets that pixel value to 1, indicating it is within the annular region.\n",
    "    4. Pixels outside this range are left as 0, indicating they are outside the annular region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f807ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for the annular mask\n",
    "a = 40   # Inner radius\n",
    "b = 60   # Outer radius\n",
    "N = 200  # Number of rows\n",
    "M = 200  # Number of columns\n",
    "# Generate the annular mask\n",
    "mask = annularMask(a, b, N, M)\n",
    "# Plot the annular mask\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(mask, cmap='jet')\n",
    "plt.title('Annular Mask')\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.colorbar(label='Mask Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c077a14",
   "metadata": {},
   "source": [
    "### The quats_to_unit_vecs function \n",
    "\n",
    "The quats_to_unit_vecs function converts a set of quaternions to unit vectors representing average projection directions. Quaternions are a way to represent rotations in three-dimensional space, and this function maps them to points on the unit sphere, effectively translating rotational information into directional vectors.\n",
    "\n",
    "    1. The input q is expected to be an array of quaternions, where each quaternion is represented by four components (q[0,:], q[1,:], q[2,:], q[3,:]) and is stored in columns of the array.\n",
    "    2. The function calculates the corresponding unit vectors for these quaternions using the formula provided. This formula maps the quaternion representation of rotations to points on the unit sphere in 3D space.\n",
    "    3. The output is an array of unit vectors (PDs), where each vector is a point on the unit sphere representing the direction of the corresponding quaternion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2189e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example quaternions (4 components each, stored in columns)\n",
    "q = np.array([[0.7071, 0.7071, 0, 0],  # Quaternion 1\n",
    "              [0, 0, 0.7071, 0.7071],  # Quaternion 2\n",
    "              [0.5, 0.5, 0.5, 0.5],    # Quaternion 3\n",
    "              [0.7071, 0, 0.7071, 0]]) # Quaternion 4\n",
    "# Convert quaternions to unit vectors\n",
    "PDs = quats_to_unit_vecs(q)\n",
    "# Plot the unit vectors on a unit sphere\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.quiver(0, 0, 0, PDs[0, :], PDs[1, :], PDs[2, :], length=1.0, normalize=True)\n",
    "# Draw a unit sphere for reference\n",
    "u, v = np.mgrid[0:2*np.pi:20j, 0:np.pi:10j]\n",
    "x = np.cos(u)*np.sin(v)\n",
    "y = np.sin(u)*np.sin(v)\n",
    "z = np.cos(v)\n",
    "ax.plot_wireframe(x, y, z, color=\"r\", alpha=0.1)\n",
    "ax.set_xlim([-1, 1])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_zlim([-1, 1])\n",
    "ax.set_xlabel('X', labelpad=5)\n",
    "ax.set_ylabel('Y', labelpad=5)\n",
    "ax.set_zlabel('Z', labelpad=0) \n",
    "plt.title('Unit Vectors Representing Quaternions on Unit Sphere')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44536a1",
   "metadata": {},
   "source": [
    "### Step 3: Distance calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e962c4a4",
   "metadata": {},
   "source": [
    "### Step 3A: Set filter parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_params = FilterParams(method='Butter', cutoff_freq=0.5, order=8)\n",
    "print(\"Filter parameters:\", filter_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0266e",
   "metadata": {},
   "source": [
    "### Step 3B: Data acquisition  \n",
    "\n",
    "Let us take the case of a single projection direction cluster (prD0) out of the 63 projection directions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff358fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = _construct_input_data(prds.thresholded_image_indices, \n",
    "                                   prds.quats_full, prds.defocus)\n",
    "sample_data = input_data[0]\n",
    "if hasattr(sample_data, '__dict__'):\n",
    "    # If the instance has a __dict__ attribute, print its keys\n",
    "    print(vars(sample_data).keys())\n",
    "elif isinstance(sample_data, dict):\n",
    "    # If the instance itself is a dictionary\n",
    "    print(sample_data.keys())\n",
    "else:\n",
    "    # If LocalInput uses a method to return its attributes as a dictionary\n",
    "    # Assuming the method is named 'to_dict()'\n",
    "    print(sample_data.to_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ad709",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_list_summary(lst, lst_name):\n",
    "    if len(lst) > 6:\n",
    "        summary_str = ', '.join(map(str, lst[:3])) + ', ..., ' + ', '.join(map(str, lst[-3:]))\n",
    "        print(lst_name + \" :\", summary_str)\n",
    "    else:\n",
    "        print(lst_name + \" :\", ', '.join(map(str, lst)))\n",
    "\n",
    "indices_list = list(sample_data.indices) if hasattr(sample_data, 'indices') else []\n",
    "quats_list = list(sample_data.quats) if hasattr(sample_data, 'quats') else []\n",
    "defocus_list = list(sample_data.defocus) if hasattr(sample_data, 'defocus') else []\n",
    "dist_file_list = [sample_data.dist_file] if hasattr(sample_data, 'dist_file') else []\n",
    "print(\"The length of the indices_list is:\", len(indices_list))\n",
    "#print_list_summary(indices_list, lst_name=\"indices_list\")\n",
    "print(\"The length of the quats_list is:\", len(quats_list[0]))\n",
    "print(\"The length of the defocus_list is:\", len(defocus_list))\n",
    "print(\"The output is saved as:\", dist_file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ee826f",
   "metadata": {},
   "source": [
    "### Step 3C: Distance calculation   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7709f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_distance_CTF_local(\n",
    "    input_data=sample_data,\n",
    "    filter_params=filter_params,\n",
    "    img_file_name=p.img_stack_file,\n",
    "    image_offsets=prds.microscope_origin,\n",
    "    n_particles_tot=len(prds.defocus),\n",
    "    relion_data=p.relion_data\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bca57bd",
   "metadata": {},
   "source": [
    "### Step 4: Post distance calculation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1eb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_file_path = sample_data.dist_file\n",
    "with open(dist_file_path, 'rb') as file:\n",
    "    dist_data = pickle.load(file)\n",
    "print(dist_data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce74472b",
   "metadata": {},
   "source": [
    "#### Visualizing the distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix = dist_data['D']\n",
    "# Heatmap\n",
    "print(\"The shape of the distance matrix is\", distance_matrix.shape)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(distance_matrix, cmap='viridis', xticklabels=False, yticklabels=False)\n",
    "plt.title('Distance Matrix Heatmap')\n",
    "plt.xlabel('Images')\n",
    "plt.ylabel('Images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc3030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical Clustering Dendrogram\n",
    "linked = linkage(distance_matrix, 'single')\n",
    "# Plot the dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "dendrogram(linked, orientation='top', distance_sort='descending', show_leaf_counts=True, no_labels=True)\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Images')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5302302",
   "metadata": {},
   "source": [
    "#### Visualizing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbb3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgAll = dist_data['imgAll']\n",
    "num_images_to_display = 24\n",
    "num_rows = 4\n",
    "num_cols = 6\n",
    "# Generate evenly spaced indices to select images across the dataset\n",
    "image_indices = np.linspace(0, len(imgAll) - 1, num_images_to_display, dtype=int)\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 7.5))\n",
    "axes_flat = axes.flatten()\n",
    "# Loop through the selected images and plot\n",
    "for ax, idx in zip(axes_flat, image_indices):\n",
    "    ax.imshow(imgAll[idx], cmap='gray')\n",
    "    ax.axis('off')  # Hide axes ticks\n",
    "    ax.set_title(f'Image {idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeff4ebb",
   "metadata": {},
   "source": [
    "#### Visualizing the average image for the projection direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgAvg = dist_data['imgAvg']\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(imgAvg, cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Average Image for Projection Direction')\n",
    "plt.axis('off') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
